「ディープラーニングと物理学　オンライン」とはオンラインWeb会議システムを利用したセミナーです。2023年10月より、学習物理領域セミナーと合同で開催されています。

登録する際のメールアドレスは、できるだけ大学もしくは研究機関のものをご使用ください。

* ZoomのミーティングURLおよびパスワードは、先着順300名様に限り、登録されたメールアドレスに送信されます。転載・転送は控えてください。
* URLが掲載されたメールは当日の朝までに送られます。

* 参加したい方は下記よりお申し込みください。毎回開催時に参加URLのついたアナウンスのメールを送信します。<br>
[登録フォーム](https://docs.google.com/forms/d/e/1FAIpQLSfiSawgWi9BZF7pFmGsTDD7bOX4kPZKX-BRtPJ4PmwhKe-22A/viewform) <br>
(締切は前日の夜11時までとします)

* 解約フォームは下記でございます。<br>
[解約フォーム](https://docs.google.com/forms/d/e/1FAIpQLSePLXuRLkxVK3CdR_aZBup166mRROk5Z3Ty4zN86_7vSLON2w/viewform)

<!--
* 2021年2月以降の講演者の推薦お待ちしています<br>
[講演者の推薦はこちら](https://docs.google.com/forms/d/e/1FAIpQLSfLv6BbJ_s5X-bKiGxaUYWALFixWi23ZRv3EcYFxUgE1R479w/viewform)
-->

* 参加時の表示名は「登録時の名前＠登録した機関名」に設定してください。
* ノイズを防ぐためのミュートへご協力ください。

DLAP世話人:　橋本幸士（京都大）、富谷昭夫（東京女子大）、永井佑紀（東京大）、田中章詞（理研AIP/iTHEMS）（順不同)

領域セミナー世話人：橋本幸士（京都大）、広野雄士（大阪大）、三内顕義（京都大）、金子隆威（上智大）（順不同）

本セミナーシリーズは、科学研究費補助金学術変革領域研究(A)「[学習物理学の創成](https://mlphys.scphys.kyoto-u.ac.jp/)」の補助を受けております。

* [第25回領域セミナ・第77回DLAP：　三角 樹弘 氏 「What can PINN do? -PDE, lattice fermions and topology-」](#第25回学習物理領域セミナー第77回dlap) 1/29
* [第24回領域セミナ・第76回DLAP：　高橋 智 氏 「遺伝的アルゴリズム/強化学習で探るインフレーション宇宙論」](#第24回学習物理領域セミナー第76回dlap) 1/15
* [第23回領域セミナ・第75回DLAP：　森永 真央 氏 「高エネルギー物理実験におけるニューラルネットワーク応用について」](#第23回学習物理領域セミナー第75回dlap) 12/18
* [第22回領域セミナ・第74回DLAP：　笠置 歩 氏 「深層学習による基礎物理測定データ解析: 分類・検出・回帰予測、マルチモーダルへの発展」](#第22回学習物理領域セミナー第74回dlap) 12/4
* [第21回領域セミナ・第73回DLAP：　竹田 晃人 氏 「行列分解問題へのベイズ統計学的アプローチ」](#第21回学習物理領域セミナー第73回dlap) 11/20
* [第20回領域セミナ・第72回DLAP：　棚橋 典大 氏 「物理的ニューラルネットによる極小曲面の生成とその応用」](#第20回学習物理領域セミナー第72回dlap) 11/6
* [第19回領域セミナ・第71回DLAP：　谷地村 敏明 氏 「最適輸送理論の単一細胞データ解析への応用：細胞分化ダイナミクスの推定」](#第19回学習物理領域セミナー第71回dlap) 7/24
* [第18回領域セミナ・第70回DLAP：　谷口 忠大 氏 「科学のモデルとしての集合的予測符号化：生成科学に向けた記号創発システムアプローチ」](#第18回学習物理領域セミナー第70回dlap) 6/26
* [第17回領域セミナ・第69回DLAP：　阪上雅昭 氏 「変分オートエンコーダーによる乳幼児語彙発達の解析」](#第17回学習物理領域セミナー第69回dlap) 4/24
* [第16回領域セミナ・第68回DLAP：　小渕 智之 氏 「圧縮センシングの理論と最近の進展」](#第16回学習物理領域セミナー第68回dlap) 2/6
* [第15回領域セミナ・第67回DLAP：　伊藤 創祐 氏 「最適輸送と非平衡熱力学: 拡散モデルへの応用」](#第15回学習物理領域セミナー第67回dlap) 1/30
* [第14回領域セミナ・第66回DLAP：　原田 健自 氏 「テンソル木を用いた生成モデルがデータ内の隠れた関係性を抽出する」](#第14回学習物理領域セミナー第66回dlap) 1/16
* [第13回領域セミナ・第65回DLAP：　堀江 正信 氏 「局所保存性・相似変換対称性を満たす機械学習モデルによる数値流体力学」](#第13回学習物理領域セミナー第65回dlap) 12/19
* [第12回領域セミナ・第64回DLAP：　今田 正俊 氏 「フェルミマシン」](#第12回学習物理領域セミナー第64回dlap) 11/28
* [第11回領域セミナ・第63回DLAP：　竹内 駿 氏 「AI社会実装の最前線－宇宙物理との関連も交えて」](#第11回学習物理領域セミナー第63回dlap) 11/14
* [第10回領域セミナ・第62回DLAP：　広野 雄士 氏 「経路積分を用いた拡散モデルの定式化」](#第10回学習物理領域セミナー第62回dlap) 10/24
* [第9回領域セミナ・第61回DLAP：　白崎 正人 氏 「宇宙大規模構造の深層学習生成モデル」](#第9回学習物理領域セミナー第61回dlap) 10/3
* [第8回領域セミナ・第60回DLAP：　磯村 拓哉 氏 「自己組織化系のベイズ力学」](#第8回学習物理領域セミナー第60回dlap) 7/4
* [第7回領域セミナ・第59回DLAP：　吉中 譲次郎 氏 「Neural network representation of quantum systems」](#第7回学習物理領域セミナー第59回dlap) 6/13
* [第6回領域セミナ・第58回DLAP：　池 祐一　氏 「パーシステントホモロジーと機械学習」](#第6回学習物理領域セミナー第58回dlap) 2/15
* [第5回領域セミナ・第57回DLAP：　乾幸地　氏 「自動微分を用いた欲しい性質をもつハミルトニアンの逆設計: バンドトポロジーと量子エンタングルメントへの応用」](#第5回学習物理領域セミナー第57回dlap) 12/14
* [第4回領域セミナ・第56回DLAP：　太田敏博　氏 「Hopfield/Mixer 対応：MetaFormer のより良い理解に向けて」](#第4回学習物理領域セミナー第56回dlap) 12/8
* [第3回領域セミナ・第55回DLAP：　玉井敬一　氏 「深層ニューラルネットワークと非平衡臨界現象：ディープラーニングに潜む普遍的な法則の探求」](#第3回学習物理領域セミナー第55回dlap) 11/9
* [第2回領域セミナ・第54回DLAP：　高木志郎　氏 「研究ができる人工知能の実現へ向けた課題の検討」](#第2回学習物理領域セミナー第54回dlap) 10/26
* [第1回領域セミナ・第53回DLAP：　橋本幸士　氏 「Neural Polytopes」](#第1回学習物理領域セミナー第53回dlap) 10/5
* [第52回：　Stefan Heusler　氏 「The impact of machine learning on science education」](#第52回) 9/7
* [第51回：　田中章詞　氏 「近年の深層学習について」](#第51回) 6/1
* [第50回：　永井佑紀　氏 「機械学習分子シミュレーションを用いた、準結晶における高次元性の解析」 ](#第50回) 4/27

2022年以前の講演は[こちら](#過去の講演)


# 第25回学習物理領域セミナー＋第77回DLAP
日時：1月29日10:30~11:30(JST)<br>
発表者： 三角 樹弘 氏 (近畿大学 大学院総合理工学研究科)<br>
場所（ハイブリッド）：京都大学理学研究科5号館 501<br>
発表題目：What can PINN do? -PDE, lattice fermions and topology-<br>
概要：Physics-Informed Neural Networks (PINN) は，物理法則を損失関数に組み込むことで微分方程式を解く強力な手法として注目を集めている．本講演では，非線形偏微分方程式から格子場の理論に至るまで，理論物理学におけるPINNの可能性を探る．まず，自己重力系量子物質を記述するシュレディンガー-ニュートン方程式への適用例を紹介した後，今回の主眼である格子フェルミオンとトポロジーへの応用について議論する．ここでは，ニューラルネットワーク(NN)を用いて格子上のカイラルフェルミオンを構成する新しいアプローチを考える．具体的には，Ginsparg-Wilson (GW) 関係式や局所性を物理的制約として課すことで，NNがOverlapフェルミオンのスペクトル演算子を学習できることを示す．学習された演算子のトポロジカルな性質がU(1)ゲージ場中のスペクトルフローを通してAtiyah-Singerの指数定理を満たすことを見る．さらに，物理的要請のみからNNが厳密なGW関係式そのものを「再発見」した結果についても触れ，場の理論における対称性の探索に対するデータ駆動型アプローチの可能性を議論する．<br>

# 第24回学習物理領域セミナー＋第76回DLAP
日時：1月15日10:30~11:30(JST)<br>
発表者： 高橋 智 氏 (佐賀大学 大学院理工学研究科)<br>
場所：ZOOM (オンラインのみ、上智大学四谷キャンパス 理工学部9号館 254A にてオンライン配信も行います)<br>
発表題目：遺伝的アルゴリズム/強化学習で探るインフレーション宇宙論<br>
[講演スライド](./slides/2026_1_15_ML_seminar_Takahashi.pdf)<br>
概要：宇宙極初期に起こったとされる急激な加速膨張期であるインフレーションは，標準ビッグバン宇宙論の諸問題を解決するだけでなく，宇宙背景放射の揺らぎ，宇宙の大規模構造など現在の宇宙の構造の起源も説明する。インフレーションはインフラトン場と呼ばれるスカラー場によって駆動されると考えれらているが，その背後にある具体的な物理機構（どのような理論／モデルがインフレーションを記述しているか）は未だ明らかになっていない。モデルの枠組みをある程度特定すれば，近年の精密な宇宙観測データより，モデルに対する厳しい制限が課されつつある一方，なるべくモデル依存性を排し，一般的にインフレーションモデル（具体的にはインフラトン場のポテンシャルなど）をデータから再構築しようとすると，関数自由度の高さゆえに従来のパラメータ探索手法は現実的でなくなってしまう。本講演では，出来る限り一般的な枠組みのもとでインフレーションモデルの再構築を目指し，遺伝的アルゴリズム／強化学習の手法を用いるアプローチについて議論する。インフラトン場ポテンシャルの再構築手法を，複数場モデルへの拡張も含めて検討し，従来の手法との比較を行う。さらに，これらの手法がインフレーションにとどまらず，宇宙進化の理解において有用な解析手段となり得る可能性についても簡単に触れる。<br>

# 第23回学習物理領域セミナー＋第75回DLAP
日時：12月18日10:30~11:30(JST)<br>
発表者： 森永 真央 氏 (東京大学 素粒子物理国際研究センター)<br>
場所（ハイブリッド）：上智大学四谷キャンパス 理工学部9号館 254A<br>
発表題目：高エネルギー物理実験におけるニューラルネットワーク応用について<br>
[講演スライド](./slides/ML-Seminar-202512.pdf)<br>
概要：素粒子実験における機械学習の応用や利用の歴史は30年ほどになる。近年のニューラルネットワークの発展に伴って利用される技術や手法も進化しており、その範囲も拡大されてきた。本講演では、高エネルギー実験屋の好みや基礎的な実験の考え方について紹介し、特にTransformerや拡散モデルなどの最新技術を取り込んだ研究について紹介する。時間が許せば発表者の最近の研究であるジェットを言語化する研究についても紹介する。<br>

# 第22回学習物理領域セミナー＋第74回DLAP
日時：12月4日10:30~11:30(JST)<br>
発表者： 笠置 歩 氏 (同志社大学 研究開発推進機構)<br>
場所：ZOOM (オンラインのみ)<br>
発表題目：深層学習による基礎物理測定データ解析: 分類・検出・回帰予測、マルチモーダルへの発展<br>
[講演スライド](./slides/ML_Physics_seminar_kasagi.pdf)<br>
概要：深層学習の優れた汎化性能は基礎科学の実験データ解析にも広く応用されている。本講演では講演者らがこれまでに深層学習を導入して取り組んできた原子核物理実験のための画像解析、イオン源制御手法について紹介する。さらに、近年発展が著しいVision Language Modelに代表されるマルチモーダルモデルを用いた解析手法のアイデアについても議論する。<br>

# 第21回学習物理領域セミナー＋第73回DLAP
日時：11月20日10:30~11:30(JST)<br>
発表者： 竹田 晃人 氏 (茨城大学 応用理工学野)<br>
場所：ZOOM (オンラインのみ、上智大学四谷キャンパス 理工学部9号館 254A にてオンライン配信も行います)<br>
発表題目：行列分解問題へのベイズ統計学的アプローチ<br>
[講演スライド](./slides/takeda_20251120.pdf)<br>
概要：行列分解問題は与えられた原行列（行列形式のデータ）を二つの行列積に分解する問題であり、問題の設定次第では分解後の各行列から原行列の適切な特徴量を取り出せるため、機械学習では重要な研究対象の一つとされる。なお行列分解問題の理論解析にはベイズ統計学に基づくアプローチが知られ、これは統計物理学的解析手法とも密接に関連している。本講演ではベイズ統計学に基づく行列分解問題の解析の基礎や過去の研究を概観した後に、講演者らが行った変分ベイズ法によるスパース行列分解問題の解析、および連想記憶模型であるHopfield模型と行列分解問題との関係性を利用した解析を紹介する。<br>
参考文献：<br>
R. Kawasumi and K. Takeda, Neural Comput. 35, 1086 (2023)<br>

# 第20回学習物理領域セミナー＋第72回DLAP
日時：11月6日10:30~11:30(JST)<br>
発表者： 棚橋 典大 氏 (京都大学 大学院理学研究科)<br>
場所：ZOOM (オンラインのみ、上智大学四谷キャンパス 理工学部9号館 254A にてオンライン配信も行います)<br>
発表題目：物理的ニューラルネットによる極小曲面の生成とその応用<br>
[講演スライド](./slides/PINN_dlap-20251106.pdf)<br>
概要：本講演では、機械学習を用いた微分方程式の解法として注目されているPhysics-Informed Neural Network（PINN）を、重力理論およびその応用分野に典型的に現れる微分方程式に適用する試みを紹介する。PINNの実用性と課題、従来手法と比べた場合の特性を検証するため、重力理論研究の文脈で議論される問題（曲がった時空における弦や極小曲面の構成）に注目して数値解の構成を試みる。特に、数値計算領域が動的に変化したり、通常数値解の構成が困難となる特異点が存在する場合について、PINNがいかなる利点をもたらしうるかを紹介する。また、本手法を素粒子論研究に応用する試み（グルーオン散乱振幅の計算）についても報告する。<br>
参考文献:<br>
K. Hashimoto, K. Kyo, M. Murata, G. Ogiwara, N. Tanahashi,<br>
"Physics-informed neural network solves minimal surfaces in curved spacetime", arXiv:2509.10866 [hep-th]<br>
"Gluon scattering amplitudes with instantons and minimal surfaces with topology change", arXiv:2509.10865 [hep-th]<br>

# 第19回学習物理領域セミナー＋第71回DLAP
日時：7月24日10:30~11:30(JST)<br>
発表者： 谷地村 敏明 氏 (東北大学 数理科学共創社会センター)<br>
場所（ハイブリッド）：上智大学四谷キャンパス 理工学部9号館 254A<br>
発表題目：最適輸送理論の単一細胞データ解析への応用：細胞分化ダイナミクスの推定<br>
[講演スライド](./slides/谷地村_学習物理領域セミナー送付用.pdf)<br>
概要：近年，単一細胞RNAシーケンス(scRNA-seq)技術をはじめとする先進的な測定技術の進展により，発生や分化に伴う細胞状態の変化を単一細胞レベルで観測できるようになった．しかしながら，実験で得られるのは離散時点での細胞状態のスナップショットであり，そこから連続的な細胞分化ダイナミクスを推定するには新たな数理的枠組みが必要である．本講演では，エントロピー正則化混合ガウス最適輸送理論(Entropic Gaussian mixture Optimal Transport; EGOT)に基づく包括的細胞分化ダイナミクス推定ソフトウェアscEGOTを紹介する．scEGOTは従来手法が構築してきた細胞状態グラフに加え，各細胞における遺伝子発現の速度，その動態(アニメーション)，分化可塑性を表すポテンシャル地形，およびそれを形作る遺伝子制御ネットワークを，一貫した枠組みかつ非常に低い計算コストで推定することが可能である．このscEGOTをiPS細胞から始原生殖細胞(PGC)を誘導する系の時系列scRNA-seqデータに適用し，PGC前駆細胞とその誘導過程における新規マーカー遺伝子を同定した結果についても報告する．<br>
参考文献:<br>
Yachimura, T. et al. scEGOT: single-cell trajectory inference framework based on entropic Gaussian mixture optimal transport. BMC Bioinformatics 25, 388 (2024).<br>

# 第18回学習物理領域セミナー＋第70回DLAP
日時：6月26日10:30~11:30(JST)<br>
発表者： 谷口 忠大 氏 (京都大学 情報学研究科)<br>
場所：ZOOM (オンラインのみ、上智大学四谷キャンパス 理工学部9号館 254A にてオンライン配信も行います)<br>
発表題目：科学のモデルとしての集合的予測符号化：生成科学に向けた記号創発システムアプローチ<br>
[講演スライド](./slides/250626-学習物理学-ai-science-tanichu-still.pdf)<br>
Collective Predictive Coding as a Model of Science: A Symbol Emergence Systems Approach Towards Generative Science<br>
概要：近年、生成AIの発展により、科学的活動を支援したり代替したりするAIエージェント及びAIロボットの存在が現実味を帯びてきている。そこから生まれる生成科学の概形が少しずつ見えてきているように思われる。一方で、現状から近未来における議論はその殆どが科学に関わる人間のパッチワーク的な置き換え議論に終止しているように見える。本講演では、科学的知識の生成過程を、集合的予測符号化（Collective Predictive Coding, CPC）の枠組みで捉えることによって、「生成科学（Generative Science）」を理論的に定式化しようとする試みを紹介する。CPC仮説に基づき人間およびAIエージェントによる記号創発過程を分散的なベイズ推論として位置づけた後に、これを敷衍することで、科学的活動全体を集合的予測符号化の枠組みで捉える科学活動のシステム論に関して議論する。<br>
関連論文：<br>
Taniguchi, T., Takagi, S., Otsuka, J., Hayashi, Y., & Hamada, H. T. (2025).<br>
Collective predictive coding as model of science: Formalizing scientific activities towards generative science.<br>
Royal Society Open Science (in press) [arXiv:2409.00102].<br>
参考リンク:<br>
https://cpc-ms.github.io/<br>
https://www.youtube.com/watch?v=2uatQVyEheI<br>

# 第17回学習物理領域セミナー＋第69回DLAP
日時：4月16日10:30~11:30(JST)<br>
発表者：阪上雅昭 氏 (京都大学人間・環境学研究科 名誉教授)<br>
場所：ZOOM (オンラインのみ、上智大学四谷キャンパス 理工学部9号館 254A にてオンライン配信も行います)<br>
発表題目：変分オートエンコーダーによる乳幼児語彙発達の解析<br>
[講演スライド](./slides/学習物理20250424-変分オートエンコーダーによる乳幼児の表出語彙発達（公開用）.pdf)<br>
概要：人間の発達や行動の変化を自己組織化現象として理解しようとするダイナミックシステム・アプローチが，発達心理学の分野で提案されている[1]．これは，物理学で発展した自己組織化や相転移の概念を，人間の発達理解に応用しようとする試みである．私たちはこのパラダイムを乳幼児の言語発達に適用し，胚性詞仮説を提唱・検証してきた[2]．この仮説は，乳幼児が当初，語をことばの出来事として認識し（胚性詞），その後，名詞や動詞へと意味が分化していくというものであり，この意味分化をモノおよび行為アトラクターへの分岐として捉えている．<br>
本講演では，乳幼児語彙発達質問紙（CDI）[3]による多言語データに対し，変分オートエンコーダー（VAE）を用いて潜在空間を構築し，語の発達過程や個体の発達軌道を可視化・定量化する試みを紹介する[4]．質問紙という高次元データをVAEの潜在空間（2または3次元）に縮減することにより，言語ごとに異なる発達の特徴を「かたち」として可視化することができる．さらに，VAEのdecoderによりデータを生成することで，潜在空間の解釈が容易になり，語の意味の分化過程や名詞・動詞等の獲得に関わる発達のアトラクター構造を明らかにすることができる．<br>
参考文献:<br>
[1] E.テーレン，L. スミス　発達へのダイナミックシステム・アプローチ　新曜社<br>
[2] H.Hagihara, H.Yamaomoto, Y.Moriguchi, M.Sakagami, Cognition 226
105177 (2022)<br>
[3] Wordbank, An open database of children's vocabulary development,
http://wordbank.stanford.edu/<br>
[4] 萩原広道, 水谷天智, 山本寛樹, 阪上雅昭, “変分オートエンコーダーを用いた乳幼児期の語彙発達過程の探索”,
認知科学30(4), (2023) 499-514<br>



# 第16回学習物理領域セミナー＋第68回DLAP
日時：2月6日10:30~11:30(JST)<br>
発表者：小渕 智之 氏 (京都大学大学院 情報学研究科)<br>
場所（ハイブリッド）：京都大学 理学部５号館 501号室<br>
発表題目：圧縮センシングの理論と最近の進展<br>
[講演スライド](./slides/MLPhys_20250206.pdf)<br>
概要：サンプリング定理は，原信号を完全復元するために必要な観測数を簡潔な形で与える，信号処理における金字塔的結果の1つである．ここに，原信号が適切な基底で表現されたときにスパースになるという仮定を追加導入することで，サンプリング定理が与える観測数の限界を超えることができる．これが圧縮センシングである[1]．理論的に興味深いのは，どのような定式化をするとどこまで観測数を減らすことができるか，という点であり，高次元確率論や統計物理の視点から徹底的に解析された[2-5]．その一方，圧縮センシングをどのように実応用していくかという研究も盛んに行われ，医療や天文学において顕著な成果が得られている．本講演では，圧縮センシングの理論を簡単におさらいしたあと，最近我々が行った分光分析への応用研究[6]を紹介する．<br>
参考文献:<br>
[1] M. Elad: Sparse and redundant representations: From theory to applications in signal and image processing, Springer Science & Business Media (2010)<br>
[2] E. J. Candes and T. Tao: Decoding by linear programming, IEEE Trans. Inf. Th., vol. 51, no. 12, 4203, (2005)<br>
[3] D. L. Donoho, J. Tanner: Sparse nonnegative solution of underdetermined linear equations by linear programming, Proc. Natl. Acad. Sci., 102, 27, 9446 (2005)<br>
[4] Y. Kabashima, T. Wadayama, T. Tanaka J. Stat. Mech., L09003 (2009)<br>
[5] D. L. Donoho, A. Maleki, A. Montanari: Message-passing algorithms for compressed sensing, Proc. Natl. Acad. Sci., 106, 45, 18914 (2009)<br>
[6] K. Uemura, T. Obuchi and T. Tanaka: Sparse Modeling for Spectrometer Based on Band Measurement, IEEE Trans. Sig. Proc. 72, 1724 (2024)<br>

# 第15回学習物理領域セミナー＋第67回DLAP
日時：1月30日10:30~11:30(JST)<br>
発表者：伊藤 創祐 氏 (東京大学 理学系研究科 生物普遍性研究機構)<br>
場所（ハイブリッド）：上智大学四谷キャンパス 理工学部9号館 254A<br>
発表題目：最適輸送と非平衡熱力学: 拡散モデルへの応用<br>
[講演スライド](./slides/gakushu-Ito.pdf)<br>
概要：物をできるだけコストが少ないように運ぶ最適な方法は何だろうか。このような素朴な疑問は18世紀に数学者ガスパール=モンジュに提案されて以降、最適輸送理論と呼ばれる数学として微分幾何学や情報理論、偏微分方程式論などのさまざまな観点から発展を遂げてきた[1]。特に近年では最適輸送理論にて導入される距離の一種を用いた機械学習の手法としても興味を急速に持たれ始めている。一方で、最適輸送理論は非平衡熱力学や流体力学などの物理学と情報理論や微分幾何学などの数学をつなぐ接点としても興味深い。我々は非平衡熱力学と最適輸送理論の関係についてさまざまな研究を行ってきたが、本講演ではその一部(例えば[2]など)を紹介し、またさらに生成AIの手法である拡散モデルにおける最適輸送理論の応用[3]と、非平衡熱力学的な手法の有用性[4]について議論を行いたい。<br>
[1] Villani, C. (2009). Optimal transport: old and new (Vol. 338, p. 23). Berlin: springer.<br>
[2] Ito, S. (2024). Geometric thermodynamics for the Fokker–Planck equation: stochastic thermodynamic links between information geometry and optimal transport. Information Geometry, 7(Suppl 1), 441-483.<br>
[3] Lipman, Y., Chen, R. T., Ben-Hamu, H., Nickel, M., & Le, M. (2022). Flow matching for generative modeling. arXiv preprint arXiv:2210.02747.<br>
[4] Ikeda, K., Uda, T., Okanohara, D., & Ito, S. (2024). Speed-accuracy trade-off for the diffusion models: Wisdom from nonequilibrium thermodynamics and optimal transport. arXiv preprint arXiv:2407.04495.<br>

# 第14回学習物理領域セミナー＋第66回DLAP
日時：1月16日10:30~11:30(JST)<br>
発表者：原田 健自 氏 (京都大学大学院 情報学研究科)<br>
場所（ハイブリッド）：京都大学 理学部５号館 511号室<br>
発表題目：テンソル木を用いた生成モデルがデータ内の隠れた関係性を抽出する<br>
[講演スライド](./slides/talk20250116_harada.pdf)<br>
概要：ボルンマシンと呼ばれる量子状態の観測結果を基にした生成モデルが提案され[1]、量子コンピュータの応用例として注目されています[2]。一方、ボルンマシンの量子状態をテンソルネットワーク（テンソル分解）で表現することにより、古典計算機でも効率よく実行できる手法も興味深いものです[1]。実際、テンソルネットワークを用いることで、量子回路によるボルンマシンのパラメータ最適化問題を解決できることが示されています[3]。しかし、このアプローチには、テンソルネットワークの構造に性能が大きく依存するという課題があります[4]。我々の最近の研究[5]では、データ内の相互情報量に着目し、ツリーテンソルネットワーク（テンソル木）を用いたボルンマシンにおいて、ネットワーク構造を動的に改善する手法を提案しました。その結果、ボルンマシンの性能向上に加えて、ネットワーク構造からデータ内の関係性を抽出できることが明らかになりました。講演では、ランダムパターン、手書き文字画像、ベイジアンネットワーク、株価の揺らぎなどのデータに適用した実例を紹介します。近年、パラメータ圧縮の観点から機械学習においてテンソル分解が多く用いられており、ネットワーク最適化はその性能向上に貢献する有望なアプローチとして期待できます。<br>
[1] Han Z Y, Wang J, Fan H, Wang L and Zhang P, Unsupervised
Generative Modeling Using Matrix Product States, Physical Review X 8,
031012(2018).<br>
[2] Coyle B, Mills D, Danos V and Kashefi E, The Born supremacy:
quantum advantage and training of an Ising Born machine, npj Quantum
Information 6, 60(2020).<br>
[3] Rudolph M S, Miller J, Motlagh D, Chen J, Acharya A and
Perdomo-Ortiz A, Synergistic pretraining of parametrized quantum
circuits via Tensor networks, Nature Communications 14, 8367(2023).<br>
[4] Cheng S, Wang L, Xiang T and Zhang P, Tree tensor networks for
generative modeling, Physical Review B 99, 155131(2019).<br>
[5] Harada K, Okubo T, and Kawashima N, Tensor tree learns hidden
relational structures in data to construct generative models,
arXiv:2408.10669.<br>

# 第13回学習物理領域セミナー＋第65回DLAP
日時：12月19日10:30~11:30(JST)<br>
発表者：堀江 正信 氏 (株式会社ＲＩＣＯＳ)<br>
場所（ハイブリッド）：上智大学四谷キャンパス 理工学部9号館 254A<br>
発表題目：局所保存性・相似変換対称性を満たす機械学習モデルによる数値流体力学<br>
[講演スライド](https://speakerdeck.com/yellowshippo/ju-suo-bao-cun-xing-xiang-si-bian-huan-dui-cheng-xing-woman-tasuji-jie-xue-xi-moderuniyorushu-zhi-liu-ti-li-xue)<br>
概要：空間局所的な保存性や相似変換に対する対称性は、多くの物理現象にみられる基礎的な性質である。
しかしながら、典型的な機械学習モデルはそのどちらも満たしておらず、そのことによりモデルの信頼性や汎用性が低下してしまい、予測結果の活用が難しいという課題があった。
そこで本講演では、多様な空間構造を取り扱える機械学習モデルであるグラフニューラルネットワーク (GNN) が局所保存性を満たす必要十分条件を示した論文 [1] の内容をもとに、局所保存性・相似変換対称性を厳密に満たす機械学習モデルの構成方法について紹介する。
具体的には、局所保存性を満たすことで知られる古典的な数値解析手法である有限体積法 (FVM) と GNN との類似性に着目することで、両者の長所を活かした数理モデルが構成できることをみる。
複雑な流動・輸送現象を用いた数値実験において、本手法は高い精度と計算効率性を両立しているだけでなく高い時空間汎化性能を示すことが実証されており、こちらもあわせて紹介する。
本研究に代表される数値解析手法と機械学習手法の融合手法は、データに対する適応能力と信頼性を兼ね備えた予測モデルを得るための有望な方法論として期待できるため、この講演が新たなパラダイム創出の一助となれば幸いである。<br>
参考文献:<br>
[1] M. Horie and N. Mitsume. Graph Neural PDE Solvers with Conservation and Similarity-Equivariance. In International Conference on Machine Learning (ICML), 2024.<br>

# 第12回学習物理領域セミナー＋第64回DLAP
日時：11月28日10:30~11:30(JST)<br>
発表者：今田 正俊 氏 (上智大学/東京大学)<br>
場所（ハイブリッド）：上智大学四谷キャンパス 理工学部9号館 254A<br>
発表題目：フェルミマシン<br>
[講演スライド](./slides/2024.11.28_FermiMachine_presentation_imada.pdf)<br>
概要：格子上の量子多体問題を解き基底状態を求めるソルバーとしてニューラルネットワークを利用する手法が発展している.
量子スピン模型に対して, 制限ボルツマンマシンを使う方法が提案され[1],
従来のペア積波動関数を用いる変分モンテカルロ法と組み合わせることによって, 高い精度を達成した[2].
機械学習を用いる量子多体ソルバーは今のところ, 手法のベンチマークにとどまるものがほとんどであるが,
この手法はベンチマークを超えて正方格子上のフラストレーションのあるハイゼンベルク模型に適用され,
量子スピン液体相の存在を高精度で確証した[3]. また深層ボルツマンマシンに拡張され,経路積分法にマップし得ることも示された[4].
一方フェルミオンで表わされる遍歴電子系に対しても制限ボルツマンマシンは拡張された[2].
この手法は分子性結晶dmit塩や銅酸化物の第一原理有効ハミルトニアンに適用され,
物性物理学の難問である量子スピン液体や高温超伝導の物質依存性の再現や、そこで見出される、電子や電子スピンの分数化という、強相関電子系の示す新しい様相の解明などで貢献している[5,
6].
以上の進展にもかかわらず,フェルミ粒子系への応用については, 深層ニューラルネットワークでの符号問題や,
フェルミ多体波動関数の表現にとって本質的に重要な,「少ない計算コストで波動関数の節をどう精度よく表わすか？」「遠方の量子もつれをどう効率的に表わすか？」という課題は十分解決されてはいない.
例えばボルツマンマシンの隠れ変数は古典変数であるイジングスピンであるが, イジングスピンが波動関数の節や量子もつれを表現し得る道筋はよくわかっていない.
一方, 上述のニューラルネットワークの応用は強相関電子系が示す電子の分数化の傾向を明らかにし, アルゴリズムのヒントを与えている[6,7].
本セミナーでは, 隠れ変数にフェルミオンを採用することによって, 物理的な本質としての分数化を直接表現し,
ニューラルネットワークの新たなアーキテクチャとアルゴリズムを提案する.
隠れ変数の量子化によって、ニューラルネットワーク構造のホワイトボックス化を促すと期待される。相互作用する量子多体フェルミオン系と相互作用のない多層フェルミオン系の間のマッピングが得られることは、効率的なソルバー開発とともに、量子多体系の構造解明にも寄与する可能性がある。少数サイトのハバード模型でこのニューラルネットワークの構造と表現能力を実際に吟味した結果を議論する[8].<br>
参考文献<br>
[1] G. Carlo, M. Troyer, Science, 355, 602 (2017).<br>
[2] Y. Nomura. A. S. Darmawan, Y. Yamaji, M. Imada, Phys. Rev. B 96,
205152 (2017).<br>
[3] Y. Nomura, M. Imada, Phys. Rev. X, 11, 031034 (2021).<br>
[4] G. Carleo, Y. Nomura, M. Imada, Nat. Commun. 9, 5322 (2018).<br>
[5] K. Ido, K.Yoshimi, T. Misawa, M. Imada npj Quantum Mater, 7, 48 (2022).<br>
[6] M. T. Schmid, et al., J.-B. Moree, R. Kaneko, Y. Yamaji, M. Imada,
Phys. Rev. X, 13, 041036 (2023).<br>
[7] M. Imada, J. Phys. Soc. Jpn. 90, 111009 (2021).<br>
[8] M. Imada, J. Phys. Soc. Jpn. 93, 104002 (2024).<br>

# 第11回学習物理領域セミナー＋第63回DLAP
日時：11月14日10:30~11:30(JST)<br>
発表者： 竹内 駿 氏（富士通オーストラリア／マッコーリー大学）<br>
場所：オンライン<br>
発表題目：AI社会実装の最前線－宇宙物理との関連も交えて<br>
[講演スライド](./slides/20241114_LearningPhysics_ST.pdf)<br>
概要：ディープラーニングの登場を機に、AIの進化が目覚ましい。宇宙物理学・天文学分野でも、天体分類やサロゲートモデルなどAIは積極的に活用されており、実験・理論・数値シミュレーションに続く「第4の科学」としてその地位を広げている。技術の面では、画像認識や自然言語処理に関するAIは特に社会との親和性が高く、ChatGPTを始めとする技術革新とその実用化が急速に進んでいる。
本講演では画像認識に焦点を置き、富士通でのAI研究開発の取り組み [1, 2]、および近年のAI国際会議で採択された我々の関連論文を紹介する
[3, 4]。それらは人の行動を対象とした映像分析のビジネス応用およびその学習手法に関する研究であるが、技術課題や提案手法のポイントは対象分野に依存しておらず、物理学コミュニティにも有益だろう。
また、宇宙物理学出身で企業のAI研究部門に身を置く立場から、物理学とAIとの関連にも触れる。理学と工学を始めとした学問的背景や、アカデミアと企業内研究の違いなど、物理学研究とAI研究には異なる点も少なくない。企業におけるAI研究の前線を取り上げながら、AI・宇宙物理学それぞれから触発された学際的研究トピックを例示し、AI
× 物理に向けた新たな視座を提供したい。<br>
[1] 富士通, "富士通とマッコーリー大学、ヒューマンセンシングと生成AIによるデジタルコーチングプラットフォームの産学連携拠点を設置,"
2023, https://pr.fujitsu.com/jp/news/2023/11/30.html<br>
[2] 富士通, "世界初の技術で企業ニーズに対応した特化型生成AIを自動生成！エンタープライズ生成AIフレームワークを提供," 2024,
https://pr.fujitsu.com/jp/news/2024/06/4.html<br>
[3] S. Takeuchi, F. Li, S. Iwasaki, J. Ning, and G. Suzuki,
"Unsupervised domain-adaptive person re-identification with
multi-camera constraints," in ICIP, 2022<br>
[4] T. Kikuchi and S. Takeuchi, "Self-supervised human-object
interaction of complex scenes with context-aware mixing: Towards
in-store consumer behavior analysis," in WACVW, 2024<br>

# 第10回学習物理領域セミナー＋第62回DLAP
日時：10月24日10:30~11:30(JST)<br>
発表者：広野 雄士 氏 (大阪大学大学院理学研究科物理学専攻)<br>
場所（ハイブリッド）：京都大学 理学部５号館 511号室<br>
発表題目：経路積分を用いた拡散モデルの定式化<br>
[講演スライド](./slides/領域セミナー（広野雄士氏）.pdf)<br>
概要：拡散モデルは、画像生成において高い性能を示し、幅広く活用されています。本講演では、量子力学や場の量子論で用いられる経路積分の手法を応用し、拡散モデルを定式化する新しいアプローチを紹介します。この手法により、逆過程の方程式や損失関数を物理的な観点から導出するだけでなく、確率的・決定論的サンプリング手法を統一的に扱うことが可能です。特に、拡散モデルにおけるノイズの強さを調整するパラメータが、量子力学のプランク定数に相当することを明らかにし、この類似性を基に、量子力学で確立されたWKB近似を用いて確率的サンプリングにおける尤度評価を行う新しい手法を提案します。<br>
参考文献<br>
Yuji Hirono, Akinori Tanaka, Kenji Fukushima, "Understanding Diffusion
Models by Feynman's Path Integral," Proceedings of the 41st
International Conference on Machine Learning (ICML), PMLR
235:18324-18351, 2024 [arXiv:2403.11262].<br>

# 第9回学習物理領域セミナー＋第61回DLAP
日時：10月3日10:30~11:30(JST)<br>
発表者：白崎 正人 氏(国立天文台/統計数理研究所)<br>
場所（ハイブリッド）：京都大学 理学部５号館 511号室<br>
発表題目：宇宙大規模構造の深層学習生成モデル<br>
[講演スライド](https://drive.google.com/file/d/1Hr2aJuYBvwIR2WG1faza8P6QyqWf5KN6/view)<br>
概要：宇宙大規模構造とは、宇宙の物質密度の空間分布に特徴的な網の目状の構造が見られることを指します。宇宙大規模構造の網の目の大きさは、典型的には1000万光年より長く、宇宙で最大の構造物と考えられています。現在の標準的な理解では、宇宙大規模構造の形成過程には、重力的にしか相互作用しない架空の物質（暗黒物質）の存在が必要と考えられています。暗黒物質は標準物理学に対応物がなく、その性質の解明は２１世期の現代科学の一大目標です。2030年までに行われる精密観測により、宇宙大規模構造の統計的な性質が精度よく測定される見込みです。観測結果と直接比較できる理論モデルの構築は、暗黒物質と宇宙大規模構造の関連を精査する上で喫緊の課題となっています。本発表では、近年発展が続く深層学習を用いた宇宙大規模構造の生成モデルの事例をいくつか紹介し、どういう場面で天文学者・宇宙物理学者が深層学習を利用しているのかを概観します。その後、教師なし学習を使った我々の研究成果（arXiv:2310.17141）について取り上げます。我々の研究では、既存の深層学習生成モデルの多くが、訓練時に想定したシミュレーション体積より大きいデータを作ることができないという問題に着目します。この問題を解決するため、正規乱数による簡便な生成モデルにより大きい体積を確保し、小領域に分割してスタイル変換することで、短距離でのみ重要な重力による非線形効果を効率的に取り入れるアイデアに至り、実際に数値シミュレーションを使ってこのアイデアを検証しました。宇宙の領域では、コンピュータビジョンの界隈と比べて、訓練データの数は小さくなりがちです。そういう状況でも精度が出る深層学習モデルを構築するには、何らかのトリックが必要です。先行研究や我々の研究成果を通じて、そういったトリックの実例を紹介できればと思います。<br>

# 第8回学習物理領域セミナー＋第60回DLAP
日時：7月4日10:30~11:30(JST)<br>
発表者：磯村 拓哉 氏(理化学研究所　脳神経科学研究センター)<br>
場所（ハイブリッド）：上智大学四谷キャンパス 理工学部9号館 254A<br>
[講演スライド](./slides/磯村拓哉_学習物理学セミナー20240704.pdf)<br>
発表題目：自己組織化系のベイズ力学<br>
概要：ベイズ力学は、力学系をベイズ推論として概念化するための、自由エネルギー原理を発展させた新たな分野である。しかし、現実的な自己組織化系にベイズ力学を適用するためには、その系が潜在的に持つ生成モデルの解明が不可欠である。本発表では、一般的な力学系のハミルトニアンはある種の生成モデルのクラスに対応しており、その結果、系のヘルムホルツエネルギーは同定された生成モデルの下での変分自由エネルギーと等価になることを紹介する。ヘルムホルツエネルギーを最小化する自己組織化は、系内部のハミルトニアンを環境のハミルトニアンと一致させる方向へと変化させ、その結果一般化同期が現れる。つまり、これらの自己組織化系は、相互作用する環境の変分ベイズ推論を潜在的に実行していると見なすことができる。この特性が現実の系において自然に現れることを、結合振動子、神経回路モデル、培養神経回路、量子コンピュータの例を用いて紹介する。ベイズ力学の観点は、環境と相互作用する自己組織化系の漸近的性質に関する理解と予測を可能とし、知性の創発の根底にある潜在的なメカニズムに関する洞察を与えてくれる。<br>
参考文献<br>
[1] https://arxiv.org/abs/2311.10216<br>
[2] https://www.nature.com/articles/s41467-023-40141-z<br>
[3] https://www.nature.com/articles/s42003-021-02994-2<br>

# 第7回学習物理領域セミナー＋第59回DLAP
日時：6月13日10:30~11:30(JST)<br>
発表者：吉中 譲次郎 氏(京都大学大学院理学研究科 素粒子論研究室)<br>
場所（ハイブリッド）：京都大学 理学部５号館 511号室<br>
[講演スライド](./slides/ML領域セミナートーク.pdf)<br>
発表題目：Neural network representation of quantum systems<br>
概要：幅の広いランダムニューラルネットワークは中心極限定理を用いてガウス固定点まわりの場の量子論として理解できることが知られている。この方向性とは別に、我々は、かなり広いクラスの量子系をニューラルネットワークとして表す手法を提唱した。この手法はニューラルネットワークの万能近似定理に基づいて場に対する経路積分をニューラルネットワークの重みの統計和に書き換えるというものである。この研究は比較的よく知られている量子系の物理と未だ謎の多いニューラルネットワークとをつなぐものであり、ニューラルネットワークの深い理解につながると考えている。本講演は[arXiv:2403.11420]に基づく。<br>

# 第6回学習物理領域セミナー＋第58回DLAP
日時：2月15日10:30~11:30(JST)<br>
発表者：池 祐一　氏(九州大学マス・フォア・インダストリ研究所)<br>
場所（ハイブリッド）：京都大学理学研究科5号館511号室<br>
[講演スライド](./slides/2024-02-15_Kyoto.pdf)<br>
発表題目：パーシステントホモロジーと機械学習<br>
概要：近年，位相的データ解析，特にパーシステントホモロジーは機械学習と密接に結びついて発展してきている．本講演では，パーシステントホモロジーと機械学習を組み合わせる様々な取り組みについて説明したい．データのパーシステンス図を機械学習の入力として使うという従来からの手法だけでなく，パーシステントホモロジーを⽤いたトポロジー的損失項を⽬的関数に加えて最適化することで学習器をトポロジー的にコントロールするアプローチや，機械学習モデルにパーシステントホモロジーを組み込むという比較的最近の話題にも触れる予定である．また時間があれば，ニューラルネットワークからトポロジー的な特徴量を取り出したり，パーシステンス図を計算する関数そのものをネットワークで学習したりする試みについても説明したい．<br>

# 第5回学習物理領域セミナー＋第57回DLAP
日時：12月14日10:30~11:30(JST)<br>
発表者：乾幸地　氏(東京大学大学院工学系研究科原子力国際専攻)<br>
場所（ハイブリッド）：上智大学四谷キャンパス理工学部9号館254A<br>
オンライン配信会場：京都大学理学研究科5号館511号室<br>
[講演スライド](./slides/20231214_inui.pdf)<br>
発表題目：自動微分を用いた欲しい性質をもつハミルトニアンの逆設計: バンドトポロジーと量子エンタングルメントへの応用<br>
概要：逆問題を解くことによって欲しい性質を持つハミルトニアンを自動設計することは、新しい原理や物質を発見する上で有望なアプローチである。
 我々は、自動微分を用いた汎用的な手法を開発し、以下のような様々な性質へ応用することでその有用性を実証した。<br>
 (1) 異常ホール伝導率を最大化するタイトバインディング・ハミルトニアン、<br>
 (2) 太陽光照射によって誘起される光電流を最大化するスピン電荷結合ハミルトニアン、<br>
 (3) 量子エンタングルメントを最大化する量子スピンハミルトニアン<br>
 我々のフレームワークはこれ以外の様々な系に応用が可能であり、この手法の発展が材料開発や理論研究の加速に繋がると考えている。<br>
 K. Inui and Y. Motome, Inverse Hamiltonian design by automatic differentiation, Commun. Phys. 6, 37 (2023)<br>
https://www.nature.com/articles/s42005-023-01132-0

# 第4回学習物理領域セミナー＋第56回DLAP
日時：12月8日10:30~11:30(JST)<br>
発表者：太田敏博　氏(サイバーエージェント AI Lab)<br>
場所（ハイブリッド）：上智大学四谷キャンパス理工学部9号館254A<br>
オンライン配信会場：京都大学理学研究科5号館511号室<br>
[講演スライド](./slides/main.pdf)<br>
発表題目：Hopfield/Mixer 対応：MetaFormer のより良い理解に向けて<br>
概要：近年の Transformer の目覚ましい発展・応用は自然言語処理だけでなく画像認識の分野でも顕著である。Transformer において決定的な役割を果たしていると思われていた注意機構は画像認識モデルとしては必須では無いことが実験的に示唆されており、Transformer のさまざまな変種 (MetaFormers) が提案されている。一方物理学のスピングラス模型からインスパイアされた Hopfield 模型は古くから連想記憶模型として知られており、現代的 Hopfield 模型では注意機構をも内包することが明らかとなってきた。本講演ではまず Transformer と CNN の比較および Transformer の変種の代表格である MLP-Mixer を紹介したのち、 MetaFormer の統一的理解に向けて現代的 Hopfield 模型が有用であるかもしれないことを議論する。とくに MetaFormer の新しいアーキテクチャデザイン手法として Hopfield/Mixer 対応を提案し、その帰結として理論的に導出される新しい MetaFormer モデルを紹介する。最後に Hopfield/Mixer 対応の可能な拡張やその展望について述べる。

# 第3回学習物理領域セミナー＋第55回DLAP
日時：11月9日10:30~11:30(JST)<br>
発表者：玉井敬一 氏(東大理・知の物理学研究センター)<br>
場所（ハイブリッド）：上智大学四谷キャンパス理工学部9号館254A<br>
[講演スライド](./slides/MLPhysseminar_20231109.pdf)<br>
発表題目：深層ニューラルネットワークと非平衡臨界現象：ディープラーニングに潜む普遍的な法則の探求<br>
概要：深層学習の応用が近年次々と成功を収めているが、その背後にある原理の理解は
依然として容易ではない。深層学習の原理を理解することは、学習のシステマティックな設計や
信頼性向上に資するのみならず、より広汎な多体系（たとえば現実の神経系）において
"知性"が発現する仕組みを理解する上で重要な役割を果たす可能性がある。
本講演では、「吸収状態転移」という非平衡系特有の転移現象を中心軸に据えて、
人工深層ニューラルネットワークの振る舞いを非平衡統計力学の視点で捉える試みを
紹介する。前半で神経科学・深層学習理論研究における進展の（一部）概観を通じて動機づけを
行った後、後半では、初期化人工深層ニューラルネットワークにおける信号伝搬ダイナミクスが
吸収状態転移の現象論的スケーリングの枠組みで見通しよく整理できることを提案した我々の研究
[1]について説明する。<br>
[1] KT, T. Okubo, T. V. T. Duy, N. Natori and S. Todo. arXiv:2307.02284.

# 第2回学習物理領域セミナー＋第54回DLAP
日時：10月26日10:30~11:30(JST)<br>
発表者：高木志郎　氏<br>
場所（ハイブリッド）：上智大学四谷キャンパス理工学部9号館254A<br>
[講演スライド](./slides/研究ができる人工知能の実現へ向けた課題の検討.pdf)<br>
発表題目：研究ができる人工知能の実現へ向けた課題の検討<br>
概要：機械学習は様々な研究分野に応用されて多くの科学的成果をあげている [1][2]。しかし、研究のツールとしての機械学習を超えて、自分で研究ができる人工知能を作るには、まだ多くの課題がある。本公演では、このような課題の所在について検討する。まず初めに、研究をどのような行為として特徴づけることができるかを検討する。これを基に、このような人工知能を作るために必要なものやその含意について考察する。その後、研究の自動化に関連する試みを概観する。最後に、講演者らが実施した簡単な検証の結果得られた課題も踏まえて、この人工知能の実現へ向けた課題について検討する。<br>
[1] Scientific Discovery in the Age of Artificial Intelligence<br>
[2] Artificial Intelligence for Science in Quantum, Atomistic, and Continuum Systems

# 第1回学習物理領域セミナー＋第53回DLAP
日時: 10月5日10:30-11:30(JST)<br>
発表者: 橋本幸士 氏(京都大)<br>
場所（ハイブリッド）：京都大学理学部５号館511<br>
[講演スライド](./slides/2310hashimoto.pdf)<br>
発表題目: Neural Polytopes<br>
概要：本講演ではまず、非構造化ディープニューラルネットワークによる機械学習を用いて、量子力学において基底状態だけでなく低励起状態の波動関数を計算する方法を提案する。同一粒子からなる系に対して、ボソニック系では対称化、フェルミオン系では反対称化を行う簡単な方法も提案する。また、得られた波動関数の解釈を通じて、離散幾何学と機械学習の橋渡しを行う。特に、ReLU活性化を持つ単純なニューラルネットワークが、様々な次元の単位球の近似として多面体を生成することを見出す。多面体の種類は、ユニット数や層数などのネットワークアーキテクチャによって制御される。様々な活性化関数に対して、多面体の一般化が得られ、これを我々はニューラル多面体と名付けた。これは多角形の滑らかな一般化であり、幾何学的双対性を示す。この発見は、機械学習によって曲面を近似する「生成離散幾何学」の研究の端緒となろう。また、重力の量子論に向けての応用についても議論する。<br>
参考文献<br>
[1] Koji Hashimoto, Tomoya Naito, Hisashi Naito, "Neural Polytopes", [arXiv:2307.00721](https://arxiv.org/abs/2307.00721)<br>
[2] Koji Hashimoto, Tomoya Naito, Hisashi Naito, "Multi-body wave function of ground and low-lying excited states using unornamented deep neural networks", [arXiv:2302.08965](https://arxiv.org/abs/2302.08965)

# 第52回
日時: 9月7日10:30-11:30(JST)<br>
発表者: Stefan Heusler 氏(ドイツ・ミュンスター大)<br>
[講演スライド（外部リンク）](https://padlet.com/stefanheusler/the-impact-of-machine-learning-to-science-education-9xkxzbiu9rek09br)<br>
発表題目: The impact of machine learning on science education<br>
概要：Machine learning is expected to have massive impact on society in general and on the educational system in particular. In the first part of my talk, I will raise very general questions on the actual situation, as the progress in the development of machine learning is much faster than political regulations, which is also an issue from the point of view of education, as I will show with some actual examples from Germany. In the second part of my talk, I will focus on physics education and ask the question which kind of competencies will remain important for education with the advent of machine learning - both in High school and at university. With some presumably provocative statements on which activities might be reserved for human intelligence and cannot be surpassed by machine learning, I will end the talk and welcome a vivid discussion on the question how science education must adapt to this new era.<br>
Further reading: https://www.uni-muenster.de/CeNoS/en/InterKIWWU/index.html

# 第51回
日時: 6月1日10:30-11:30(JST)<br>
発表者: 田中章詞 氏(RIKEN AIP/iTHEMS) <br>
[講演スライド](./slides/1Jun_2023_atanaka.pdf)<br>
発表題目: 近年の深層学習について<br>
概要：2012年ごろから大きく進展があった深層学習のテクニックですが、近年では更なる進化と、それに伴ってライブラリも並行して進化してきています。本講演ではその近年の深層学習技術の発展のオーバービューと最近の有用と思われるライブラリの説明をしたいと思います。


# 第50回
日時: 4月27日10:30-11:30(JST)<br>
発表者: 永井佑紀 氏(国立研究開発法人日本原子力研究開発機構　システム計算科学センター) <br>
[講演スライド](./slides/Nagai_2023_DLAP.pdf)<br>
発表題目: 機械学習分子シミュレーションを用いた、準結晶における高次元性の解析<br>
概要：本講演では、機械学習分子シミュレーションという最近非常に盛んに研究がなされている分野を概観するとともに、その応用例である準結晶における高次元性の解析について紹介する。<br>
機械学習分子シミュレーション：現実世界は原子の集合から成り立っている。つまり、原子の集合の間の相互作用がわかり、それぞれの運動をシミュレーションすることができれば、物質、材料、薬、生物、あらゆることが計算機の上で再現できることになる。しかしながら、原子の性質は量子力学が関わっているため、その相互作用を正確に評価するには極めて難しい量子多体問題を解く必要がある。さらに、原子の数は非常に多く、計算は非常に困難である。そこで、計算の困難な相互作用の評価の部分を機械学習に置き換えることで、従来の計算を数千倍以上の高速化する機械学習分子シミュレーションが登場した。本講演では、機械学習の物理学への応用として有用な例として、分野外の人にもわかりやすく機械学習分子シミュレーションについて紹介する。<br>
準結晶：準結晶とは、秩序だった結晶構造を持つにもかかわらず周期性のない物質である。これは単なる空想上の物質ではなく、1982年にDan Shechtman博士(2011年ノーベル化学賞)が発見し、結晶では決して生じない5回及び10回対称性を持つ電子線回折パターンを実験的に観測されている。また、準結晶の結晶構造は、高次元(5次元や6次元)空間における超格子の現実空間(3次元)への射影として理解することができる。本講演では、この高次元性が実際に現実世界の観測可能な物理量に反映されていることを示すため、実験と機械学習分子シミュレーションを用いて比熱を解析した結果について報告する[1]。

参考文献

[1] YN, Yutaka Iwasaki, Koichi Kitahara, Yoshiki Takagiwa, Kaoru Kimura, Motoyuki Shiga, “Atomic diffusion due to hyperatomic fluctuation for quasicrystals”, arXiv:2302.14441<br>



---

# 過去のワークショップ研究会
[Deep Learning and physics2019](http://www2.yukawa.kyoto-u.ac.jp/~koji.hashimoto/workshop/DLAP2019/)<br>
[Deep Learning and physics2018](http://www2.yukawa.kyoto-u.ac.jp/~koji.hashimoto//workshop/DLAP2018/)<br>
[Deep Learning and physics](http://www2.yukawa.kyoto-u.ac.jp/~koji.hashimoto/workshop/tsrp/Deep_Lerning.html)
<!--
[Deep Learning and physics2019](http://kabuto.phys.sci.osaka-u.ac.jp/~koji/workshop/DLAP2019/)<br>
[Deep Learning and physics2018](http://kabuto.phys.sci.osaka-u.ac.jp/~koji/workshop/DLAP2018/)<br>
[Deep Learning and physics](http://kabuto.phys.sci.osaka-u.ac.jp/~koji/workshop/tsrp/Deep_Lerning.html)
-->

---

# 過去の講演

* [2022年](#2022年)
* [2021年](#2021年)
* [2020年](#2020年)

## 2022年

* [第49回：　坂田綾香　氏 「近似確率伝搬法による一般化線形モデルの予測誤差表現について」 ](#第49回) 1/26
* [第48回：　道下佳寛　氏 「機械学習を援用した適切なフレームの探索」 ](#第48回) 1/19
* [第47回：　神野隆介　氏 「Machine Learning Post-Minkowskian Integrals」 ](#第47回) 12/22
* [第46回：　村尾美緒　氏 「完全量子学習: 未知ユニタリ変換の比較アルゴリズムと逆変換化アルゴリズム」 ](#第46回) 12/8
* [第45回：　Marcel Rodekamp　氏 「Mitigating the Hubbard Sign Problem. A Novel Application of Machine Learning」](#第45回) 11/10 <font color="red"> いつもと開催時間が異なります </font>
* [第44回：　船井正太郎　氏 「機械学習が抽出する特徴とイジング模型の相転移点」](#第44回) 10/27
* [第43回：　石川勲　氏 「可逆ニューラルネットのSobolev空間における普遍性について」](#第43回) 9/15
* [第42回：　富谷 昭夫　氏 「Finite temperature and density gauge theory with classical-quantum hybrid algorithm」](#第42回) 6/23
* [第41回：　園田 翔　氏 「一般空間上の積分表現ニューラルネットとリッジレット変換」](#第41回) 6/9
* [第40回：　Shirley Ho　氏 「INTERPRETABLE LEARNING IN PHYSICAL SYSTEMS」](#第40回) 5/26
* [第39回：　田中 章詞　氏 「モンテカルロ法による強化学習入門」](#第39回) 5/12
* [第38回：　橋本 幸士　氏 「深層学習と創発時空（ホログラフィー原理）に関する文献紹介」](#第38回) 3/10
* [第37回：　三内 顕義　氏 「Deep learning and symmetry」](#第37回) 2/17
* [第36回：　瀧 雅人　氏 「Computer VisionにおけるTransformerとMLP-Mixerの現状」](#第36回) 1/13

# 第49回
日時: 1月26日10:30-11:30(JST)<br>
発表者: 坂田綾香　氏 (統計数理研究所) <br>
[講演スライド](./slides/202301_DLAP.pdf)<br>
発表題目: 近似確率伝搬法による一般化線形モデルの予測誤差表現について<br>
概要：既知データから構成した統計モデルが、未知データを適切に表現(予測)できるかどうかは、統計的機械学習における中心的課題である。モデルの予測能力は、一般に予測誤差を用いて評価され、予測誤差の小さいモデルが、高い予測性能を持つ適切なモデルであると判断される。しかし予測誤差は定義から観測不可能であり、代わりに観測可能な推定量として情報量規準や交差検証誤差、Cp規準などが用いられる。これらの推定量は統計学的な漸近極限では一致するが、有限系では必ずしも一致しない。本発表では、一般化線形モデル(GLM)において、これらの予測誤差の推定量を議論する。線形モデルにおいては、予測誤差の推定量が解析的に求められる場合もあるが、GLMの場合はそのような性質は期待できない。そこで、事後分布の近似的評価方法である近似確率伝搬法(GAMP)を導入し、GLMにおける予測誤差の推定量を導出する。その結果として得られる予測誤差の推定量は、モデルパラメータの推定値の揺らぎにより与えられることを示す。この性質は伊庭[1]、渡辺[2]らにより指摘されてきたが、GAMPを用いることで予測誤差と揺らぎの間に明確な比例関係が導出できること、また線形モデルの結果を拡張した形式として解釈できることを説明する[3]。

参考文献

[1] 伊庭，private communication<br>
[2] S Watanabe, Jpn. J. Stat. Data Sci. (2021)<br>
[3] A Sakata, arXiv:2206.12832<br>

# 第48回
日時: 1月19日10:30-11:30(JST)<br>
発表者: 道下 佳寛　氏 (理研 CEMS) <br>
発表題目: 機械学習を援用した適切なフレームの探索<br>
[講演スライド](./slides/DLaP_20230119.pdf)<br>
近年機械学習の物理分野への応用は盛んに研究がなされているが、物理学における理論解析手法の探索に対しての機械学習の応用に関する研究は乏しい。

そもそも物理学者がどのように理論解析手法を開拓してきたのか、という事について考えた時、一つのキーワードとなるのが「スケールの分離」であろう。スケールの分離を用いると、摂動論による解析や変数の削減を行う事が出来、また人為的にスケールの分離を導入して、くりこみ群の手法を用いる事もできる。しかし一般にスケールの分離を見つける事は容易ではなく、適切なフレームをみつける(適切な射影やユニタリ変換をかます)事で、スケールの分離が明確な基底にもっていき、そこで摂動論などの解析を行う事ができる。

本研究では、この適切なフレームの探索を機械学習を援用して行う手法を提案する。機械学習を用いる事によって、人間が見つけづらい非自明なスケールの分離及びそれに付随する適切なフレームの探索を行う事が最終的な目標であるが、今回は最初の一歩として、明確なスケールの分離が存在する時に、提案する手法がそれに付随する適切なフレームを見つける事が出来る事を確かめた。(具体的な系として、周期駆動された系(2-spin系)を考え、教師なしの回帰型ニューラルネットワークを用いる。)

この際「ニューラルネットの表現能力の限界が寧ろ、適切なフレームの探索に有利に働きそうである」などいくつか面白そうな知見を得たので、それらを紹介しつつ、上手くいかなかった事についても紹介したい。

[1] [arXiv:2211.15269](https://arxiv.org/abs/2211.15269)

# 第47回
日時: 12月22日10:30-11:30(JST)<br>
発表者: 神野隆介　氏 (東大ビッグバン宇宙国際研究センター)<br>
発表題目: Machine Learning Post-Minkowskian Integrals<br>
[講演スライド](./slides/Jinno.pdf)<br>
概要：We study a neural network framework for the numerical evaluation of Feynman loop integrals, which are fundamental building blocks for perturbative computations of physical observables in gauge and gravity theories. We show that such a machine learning approach improves the convergence of the Monte Carlo algorithm for high-precision evaluation of multi-dimensional integrals compared to traditional algorithms. In particular, we use a neural network to improve the importance sampling. For a set of representative integrals appearing in the computation of the conservative dynamics for a compact binary system in General Relativity, we perform a quantitative comparison between the Monte Carlo integrators VEGAS and i-flow, an integrator based on neural network sampling.<br>
[1] Ryusuke Jinno, Gregor Kälin, Zhengwen Liu, Henrique Rubira, arXiv:2209.01091 <br>

# 第46回
日時: 12月8日10:30-11:30(JST)<br>
発表者: 村尾美緒　氏 (東大理)<br>
発表題目: 完全量子学習: 未知ユニタリ変換の比較アルゴリズムと逆変換化アルゴリズム <br>
概要：<br>
未知の量子オブジェクト(量子状態や量子変換など)に量子コンピュータをつないで特定の性質を学習することを、量子学習(quantum learning)と呼ぶ。特に、量子オブジェクトを繰り返し量子測定することによってその完全な古典的記述を求める量子トモグラフィやその後の古典情報処理を行わず、最終的に必要な答え以外の古典情報は抽出せずに完全に量子コンピュータの内部で情報処理をするタイプの量子学習は、完全量子学習(fully-quantum learning)と呼ばれる。一般的に量子オブジェクトは系のサイズに関して指数関数的なパラメータ数を持つため、量子トモグラフィで得られた古典データに基づいた古典情報処理はコストが高い。そのため、古典情報処理を用いない完全量子学習の優位性が期待できる。まず、未知の2つのユニタリ変換が同じか違うかという情報を抽出する量子学習について、完全量子学習によって理論上最も効率的な情報抽出を行うための量子アルゴリズムを考察し、利用できる未知ユニタリ変換の回数が決められている時の最適戦略を導出したことを紹介する[1]。次に、未知ユニタリ変換を有限回利用して量子コンピュータ内で学習し、その逆変換を正確に実行する完全量子学習の量子アルゴリズムを紹介する[2]。このアルゴリズムは、物理系のハミルトニアン時間発展の『時間逆回し』に対応する。<br>
参考文献：<br>
[1] Y. Hashimoto, A. Soeda and M. Murao, arXiv:2208.12519<br>
[2] M. T. Quintino, Q. Dong, A. Shimbo, A. Soeda and M. Murao, Phys. Rev. Lett. 123, 210502 (2019), S. Yoshida, A. Soeda and M. Murao, arXiv:2209.02907<br>

# 第45回
日時: 11月10日16:30-17:30(JST)<br>
発表者: Marcel Rodekamp　氏 (IAS, Julich and Julich, Forschungszentrum and Bonn U., HISKP),<br>
発表題目: Mitigating the Hubbard Sign Problem. A Novel Application of Machine Learning<br>
概要：
Many fascinating systems suffer from a severe (complex action) sign
problem preventing us from simulating them with Markov Chain Monte
Carlo. One promising method to alleviate the sign problem is the
transformation towards Lefschetz Thimbles. Unfortunately, this suffers
from poor scaling originating in numerically integrating of flow
equations and evaluation of an induced Jacobian. In this talk we present
a Neural Network architecture based on complex-valued affine coupling
layers. This network performs such a transformation efficiently,
ultimately allowing simulation of systems with a severe sign problem. We
test this method within the Hubbard Model at finite chemical potential,
modelling strongly correlated electrons on a spatial lattice of ions.
<br>
参考文献：<br>
[1] Marcel Rodekamp et al., Phys.Rev.B 106 (2022) 12, 125139

# 第44回
日時: 10月27日10:30-11:30(JST)<br>
発表者: 船井正太郎　氏 (株式会社アラヤ)<br>
発表題目: 機械学習が抽出する特徴とイジング模型の相転移点<br>
[講演スライド](./slides/Talk_221027_funai.pdf)<br>
概要：
機械学習の成功は、データの特徴を抽出して表現する能力に支えられている。
その特徴抽出の様子を調べるために、データセットに2次元イジング模型のスピン配位を、特徴抽出するautoencoderに制限ボルツマンマシン(RBM)を使ったところ、ある条件下では、相転移点付近の配位を最も特徴的と捉えて学習することがわかった[1]。
データセットの大部分が高温の（ランダムに近い）配位であっても、低温の配位がわずかに含まれていて、また配位のサイズが充分に大きければ、やはり相転移点付近の配位を特徴的と捉えて学習するようだ[2]。
これは機械学習の特徴抽出を理解する上で重要になる、非自明な現象であろうと私は考えており、RBMのweight matrixの解析結果などと共に、紹介させていただきたい。<br>
参考文献：<br>
[1] S. Iso, S. Shiba (Funai), S. Yokoo, Phys. Rev. E 97, 053304 (2018) [arXiv:1801.07172 [hep-th]].<br>
[2] S. Shiba Funai, arXiv:2111.11166 [cs.LG]. 

# 第43回
日時: 9月15日10:30-11:30(JST)<br>
発表者: 石川勲　氏 (愛媛大学)<br>
発表題目: 可逆ニューラルネットのSobolev空間における普遍性について<br>
[講演スライド](./slides/DLAP20220915.pdf)<br>
概要：
可逆ニューラルネットワークは単純な形をした可逆な写像の多重に合成することで作られるニューラルネットワークである。データ生成や転移学習など様々な応用を持つが、写像の可逆性という制限から解析が難しく実際にどれほどの表現力があるのかは知られていない場合が多かった。
本研究では可逆ニューラルネットワーク（INN）のSobolev空間における普遍性、すなわち、高階の微分係数を込めた近似能力について考察を行い、十分な表現力を持つための簡明な十分条件を証明した。またこの結果を用いてSum-of-square flow (SOS)やNeural ODE(NODE)によるINNがSobolev空間において普遍性をもつことを示した。更に、そのようなINNはTotal Variationの意味で絶対連続確率測度の空間での普遍性を持つことも示した。 <br>

# 第42回
日時: 6月23日10:30-11:30(JST)<br>
発表者: 富谷昭夫　氏 (IPUT Osaka)<br>
発表題目: Finite temperature and density gauge theory with classical-quantum hybrid algorithm<br>
[講演スライド](./slides/DLAP20220623pub.pdf)<br>
概要：

場の量子論は超弦理論や素粒子標準模型の記述に必須の理論物理学の体系であるが一般的に解析が困難であり、テイラー展開をつかった摂動論をつかって主に解析が行われている。
近年の量子コンピュータの発展により、場の量子論を研究するための量子コンピュータ向けアルゴリズムの開発が近年盛んに行われている。
本研究では、有限温度・密度における量子ゲージ理論を近未来の量子デバイスで使用可能な変分法アルゴリズム(量子古典ハイブリッドアルゴリズム)を用いて調べた。
具体的には、混合状態を含んだ密度行列を変分法で取り扱うβ-VQEを適応して、場の理論の熱・量子期待値を評価し、
質量の無いシュウィンガー模型の相図を温度と密度に沿って調べた。
本講演では、それらの結果について報告する。
<br>
[1] Akio Tomiya [arXiv:2205.08860](https://arxiv.org/abs/2205.08860/index.html) <br>

# 第41回
日時: 6月9日10:30-11:30(JST)<br>
発表者: 園田 翔　氏 (理研AIP)<br>
発表題目: 一般空間上の積分表現ニューラルネットとリッジレット変換<br>
[講演スライド](./slides/dlap202206sonoda.pdf)<br>
概要：ニューラルネットが表す関数の性質を調べるには，ニューロン毎のパラメータを調べるよりも，ニューロン集団の分布を調べる方が扱いやすいことがある．前者を連続体のLagrange表示（物質表示）に対応付けるならば，後者はEuler表示（空間表示）に対応付けられる．積分表現理論は，一つの隠れ層を構成するニューロン集団を符号付き分布として定式化する解析理論である．このアプローチの強みは，ニューラルネットが表す関数fを分布関数γに対応付ける分解作用素（リッジレット変換）が積分作用素として陽に書き下せることである．リッジレット変換は1990年代にEuclid空間上の全結合層に対してMurata, Candes, Rubin によって独立に発見されていたが，今日の多様なネットワーク構造に対するリッジレット変換は未発見であった．講演者らの最近の研究により，多様体（非コンパクト対称空間）上の全結合層や，抽象ベクトル空間上の群畳み込み層に対してリッジレット変換を系統的に導出できるようになった．本講演では，その導出方法について解説する．<br>
[1] S.Sonoda, I.Ishikawa, M.Ikeda, "Fully-Connected Network on Noncompact Symmetric Space and Ridgelet Transform based on Helgason-Fourier Analysis", to appear in ICML2022. (Preprint available at arXiv:2203.01631)<br>
[2] S.Sonoda, I.Ishikawa, M.Ikeda, "Universality of group convolutional neural networks based on ridgelet analysis on groups", arXiv:2205.14819, 2022.

# 第40回
日時: 5月26日10:30-11:30(JST)<br>
発表者: Shirley Ho　氏 (Flatiron Institute, New York University)<br>
発表題目: INTERPRETABLE LEARNING IN PHYSICAL SYSTEMS<br>
概要：This work describes how machine learning may be used to develop accurate and efficient non-linear models for complex natural systems. We combine neural networks and symbolic regression to automatically discover the governing equations and hidden properties of real physical systems from observations. We will present multiple examples ranging from solar system data to simulated cosmological dataset. More broadly this work represents a key step toward realizing the potential of machine learning for accelerating scientific discovery.

# 第39回
日時: 5月12日10:30-11:30(JST)<br>
発表者: 田中 章詞　氏 (RIKEN AIP/iTHEMS)<br>
発表題目: モンテカルロ法による強化学習入門<br>
[講演スライド](./slides/rl_dlap.pdf)<br>
概要：学習エージェントをある環境の下でどのように制御すべきか、という問題に対する一つのアプローチが強化学習です。今回の入門講義では学習エージェントの目的関数を導入し、それを改善してゆくプロセスが強化学習アルゴリズムであることを[1]に基づいて説明したのち、強化学習の文献でしばしば用いられる2次元の格子状環境（Grid world）を用いた実践を行います。<br>
[1] Reinforcement Learning: An Introduction, Richard S. Sutton and Andrew G. Barto

# 第38回
日時: 3月10日10:30-11:30(JST)<br>
発表者: 橋本 幸士　氏 (京大理)<br>
発表題目: 深層学習と創発時空（ホログラフィー原理）に関する文献紹介<br>
[講演ノート](./slides/DLAP_Koji_Mar10.pdf)<br>
概要：ニューラルネットワーク自体を重力時空とみなし、深層学習をホログラフィー原理（AdS/CFT対応）とみなす一連の研究の最新成果の一つである文献[1]を紹介する。文献[1]は文献[2]でAdS/CFT対応のCFT側の量子エンタングルメントを学習データとした時空創発が行われたことの改善であるが、[1]では重力時空の量子和を試みており、量子重力理論と深層学習の間の橋渡しにチャレンジしている点が新しい。関連領域のレビューとともに、[1][2]を紹介する。<br>
[1] Machine Learning Statistical Gravity from Multi-Region Entanglement Entropy<br>
Jonathan Lam, Yi-Zhuang You<br>
[https://arxiv.org/abs/2110.01115](https://arxiv.org/abs/2110.01115)<br>
[2] Machine Learning Spatial Geometry from Entanglement Features<br>
Yi-Zhuang You, Zhao Yang, Xiao-Liang Qi<br>
Phys. Rev. B 97, 045153 (2018) [https://arxiv.org/abs/1709.01223](https://arxiv.org/abs/1709.01223)

# 第37回
日時: 2月17日10:30-11:30(JST)<br>
発表者: 三内 顕義　氏 (理研AIP)<br>
発表題目: Deep learning and symmetry<br>
概要：点群やグラフのように数学的表記が機械の入力として受け付けない形式のデータが存在する。そのようなデータを深層学習する場合に、データのベクトル化によって生じる対称性を持った表記揺れを打ち消すような深層モデルを用意し、それによって学習を行う方法が一般的である。そのようなモデルのことを不変/同変深層モデルと呼ばれる。本講演ではレイノルズ作用素と呼ばれる作用素を用いて深層ニューラルネットを不変/同変深層モデル方法、およびそれを用いたグラフを入力とするニューラルネットの構成を紹介する。

# 第36回
日時: 1月13日10:30-11:30(JST)<br>
発表者: 瀧 雅人　氏 (立教大)<br>
発表題目: Computer VisionにおけるTransformerとMLP-Mixerの現状<br>
[講演スライド](./slides/MLPMixer.pdf)<br>
概要：深層学習の広範な分野での成功・高い性能の秘密は、単に深いニューラルネットを使うということではなく、ネットワーク構造のデザインにより様々な帰納バイアスを柔軟に実現できる点にある。その典型的な例は、画像タスクにおける畳み込みニューラルネット(CNN)である。この10年の画像タスクにおける深層学習の大きな成功も、CNNの持つ帰納バイアスをベースにしていると言って良い。<br>
　ところが2020年になり、畳み込み構造に一切依存しない深層学習によって、SOTA CNNに匹敵する性能を実現できることが判明した。この新しいモデルはVisual Transformer(ViT)と呼ばれる。ViTは自然言語処理分野において発展したself-attentionを使うことで、非局所的なパターンも動的に抽出することが可能なアーキテクチャである。また翌年にはMLP-Mixerと呼ばれる手法で、self-attentionを使わずとも、多層パーセプトロン(MLP)をベースにしたモデルだけでも同等の性能の画像認識が可能であることが判明した。<br>
　このように、現在CNNパラダイムとは全く別の画像認識の方向性が明らかになりつつある。このViT、及びMLP-Mixerの発見は、データセットサイズがスケールアップした深層学習では、必ずしもCNNのような強い帰納バイアスは必要でなくなることを実証している。また訓練データセットがスケールしていくとやがてViTがCNNを凌駕することから、場合によっては強い帰納バイアスがモデルの性能に限界をもたらすことも具体的にわかってきた。<br>
　このセミナーでは、ViTおよびMLP-Mixerの現状とこれまで判明している興味深い事実、およびその欠点について議論したい。またその上で、MLP-Mixerを改善しようと試みた最近の研究についても紹介する。




## 2021年

* [第35回：　Pim de Haan　氏 「Gauge Equivariant Mesh Convolutional Neural Networks」](#第35回) 12/9
* [第34回：　大門俊介　氏 「深層学習による量子指紋の解読」](#第34回) 11/25
* [第33回：　吉野元　氏 「深層ニューラルネットワークにおけるレプリカ対称性の破れとその空間構造」](#第33回) 11/11
* [第32回：　山内紫　氏 「Real-time dynamics of lattice field theories via machine learning」](#第32回) 10/28
* [第31回：　中郷 孝祐　氏 「PFP：材料探索のための汎用Neural Network Potential」](#第31回) 10/4(<font color="red">いつもと時間が異なります</font>)
* [第30回：　Dimitrios Bachtis　氏 「Quantum field-theoretic machine learning」](#第30回) 7/15
* [第29回：　Lei Wang　氏 「Fermi Flow: Ab-initio study of fermions at finite temperature」](#第29回) 7/1
* [第28回：　蘆田祐人　氏「差分進化を用いた最適なナノ熱機関の探索」](#第28回) 6/17
* [第27回：　今泉允聡　氏「深層学習の汎化誤差解析：損失面由来の暗黙的正則化と深層モデルの二重降下」](#第27回) 6/3
* [第26回：　パネルディスカッション「物理 x 深層学習 の未来」](#第26回) 5/20
* [第25回：　田中章詞　氏「識別器による最適輸送」](#第25回) 5/6
* [第24回：　堀江正信　氏「物理シミュレーションのための同変グラフニューラルネットワーク」](#第24回) 4/22
* [第23回：　富谷昭夫　氏「ゲージ共変なニューラルネットと4次元非可換ゲージ理論への応用」](#第23回) 4/8
* [第22回：　松原祟　氏「エネルギー保存則など望ましい性質を持つ深層学習の設計について」](#第22回) 3/11
* [第21回：　一木輝久　氏「ニューラルネットワークによる結び目の標準化」](#第21回) 2/25
* [第20回：　Hidenori Tanaka　氏 & Daniel Kunin　氏「Neural Mechanics: Symmetry and Broken Conservation Laws in Deep Learning Dynamics」](#第20回) 2/18
* [第19回：　James Halverson　氏「Neural Networks and Quantum Field Theory」](#第19回) 1/28
* [第18回：　鈴木大慈　氏「無限次元勾配ランジュバン動力学による深層学習の最適化理論と汎化誤差解析」](#第18回) 1/14

# 第35回
日時: 12月9日16:30-17:30(JST)<br>
発表者: Pim de Haan　氏 (Univ. of Amsterdam)<br>
発表題目: Gauge Equivariant Mesh Convolutional Neural Networks<br>
[講演スライド](./slides/GECNN.pdf)<br>
概要：Convolutional neural networks are widely successful in deep learning on image datasets. However, some data, like that resulting from MRI scans, do not reside on a square grid, but instead live on curved manifolds, discretized as meshes. A key issue on such meshes is that they lack a local notion of direction and hence the convolutional kernel cannot be canonically oriented. By doing message passing on the mesh and defining a groupoid of similar messages that should share weights, we propose a gauge equivariant method of building a CNN on such meshes that is direction-aware, yet agnostic to how the directions are chosen. It is scalable, invariant to how the mesh is rotated, and performs state-of-the-art on a medical application for estimating blood flow.


# 第34回
日時: 11月25日10:30-11:30(JST)<br>
発表者: 大門 俊介　氏 (東大)<br>
発表題目: 深層学習による量子指紋の解読<br>
概要：ナノ量子系の電気伝導は、一般に周期性をもたない不規則な磁場依存性を示すことが知られている。この磁気伝導度ゆらぎは、試料内で電子が複雑に散乱・干渉することで引き起こされ、試料固有の振動が観測されることから「量子指紋」と呼ばれる。一方で、不規則に振動する量子指紋を解読することは従来の解析手法では困難であり、ミクロな内部情報を抽出することはできなかった。そこで本研究では、量子指紋を解読可能な深層生成ネットワークを開発し、複雑な磁気伝導度ゆらぎからミクロな内部情報の抽出に挑戦した。講演では、開発ネットワークによる試料のミクロ構造および量子干渉情報の生成と、実験データへの応用について報告する。


# 第33回
日時: 11月11日10:30-11:30(JST)<br>
発表者: 吉野 元　氏（阪大）<br>
発表題目:深層ニューラルネットワークにおけるレプリカ対称性の破れとその空間構造<br>
[講演スライド](./slides/yoshino-dlap2021.pdf)<br>
概要：G. Parisiによってスピングラスにおいて発見されたレプリカ対称性の破れ(RSB)[1]は、
複雑な自由エネルギー地形を捉える概念として、物理、情報、生物にまたがって分野横断的に用いられている。我々は、feed-forward型の深層ニューラルネットワークを用いた機械学習の問題を統計力学的に解析する中で、ネットワークの深さ方向に空間変化する特徴的なRSB[2,3]を見出していた。フラストレーション効果が厳しい入出力層付近でRSBは最も複雑な階層構造を持ち、これがネットワークの中央部に向かって単純なものに段階的に繰り込まれてゆく。訓練データとしてランダムな入出力データを用いた場合（ランダム制約充足問題)にこの現象を見出していたが、教師ー生徒シナリオ(統計的推定)においてもノイズによってベイズ最適性が崩されゆくと同様の現象が起こることが最近わかった。これが実際の深層学習に対して示唆することを数値シミュレーションの結果も交えて議論する。<br>
[1] G. Parisi, Phys. Rev. Lett. 43, 1754 (1979). 今年のノーベル物理学賞の核となる仕事
https://www.nobelprize.org/uploads/2021/10/sciback_fy_en_21.pdf<br>
[2] H. Yoshino, SciPostPhysCore 2, 005 (2020).<br>
[3] 物理学会誌9月号(76巻9号)「最近の研究から - 深層ニューラルネットワークの解剖ー統計力学によるアプローチ」<br>

# 第32回
日時: 10月28日10:30-11:30(JST)<br>
発表者: [山内紫　氏](https://inspirehep.net/authors/1760376)（メリーランド大）<br>
[講演スライド](./slides/AI_Japan_10_2021.pdf)<br>
発表題目:Real-time dynamics of lattice field theories via machine learning (https://inspirehep.net/literature/1841031 related)<br>
（ご講演は英語）<br>
概要：Quantum chromodynamics (QCD), the underlying theory of nuclei and neutron stars, has been studied successfully by lattice QCD, a non-perturbative method for computing Feynman path integrals. However, lattice QCD calculations in Minkowski spacetime suffer from the so-called sign problem, preventing us from computing non-equilibrium properties of QCD efficiently. One way to address sign problems is to deform the contour of integration in the path integral to the complex plane. I will argue for the existence of such deformed contours that solve the sign problem completely for a wide class of lattice field theories such as Yang-Mills theories. I will also discuss numerical methods based on machine learning to find such perfect contours.<br>

# 第31回
日時：2021年10月4日16:00- (<font color="red">いつもと時間が異なります</font>)<br>
講演者：中郷 孝祐　氏（PFN)<br>
[講演スライド](https://www.slideshare.net/pfi/pfpneural-network-potential-2021104-qcmsr-dlap)<br>
発表題目：PFP：材料探索のための汎用Neural Network Potential<br>
([Quantum Computational Materials Science Roundtable](https://shinaoka.github.io/QCMSR/)との共催です)<br>
概要：
Neural Network Potential (NNP)は、Neural Network を用いて分子動力学ポテンシャルを表現するものである。本セミナーではNNP研究の流れを振り返り、どのようにNNP開発のためのデータセット収集やNeural Networkの取扱いが発展してきたのかを紹介する。
後半では、多種多様な系に対して適用可能となるように開発した汎用NNPであるPFP [1]についての解説を行う。また、PFPを用いた事例としてどのような材料探索が行えるかをその応用的な使い方とともに紹介する。 <br>
[1] PFP: Universal Neural Network Potential for Material Discovery

# 第30回
日時: 7月15日10:30-11:30(JST)<br>
発表者: Dimitrios Bachtis　氏 (Swansea University)<br>
発表題目:Quantum field-theoretic machine learning <br>
概要：
The precise equivalence between discretized Euclidean field theories and a certain class of probabilistic graphical models, namely the mathematical framework of Markov random fields, opens up the opportunity to investigate machine learning from the perspective of quantum field theory. In this talk we will demonstrate, through the Hammersley-Clifford theorem, that the $\phi^{4}$ scalar field theory on a square lattice satisfies the local Markov property and can therefore be recast as a Markov random field. We will then derive from the $\phi^{4}$ theory machine learning algorithms and neural networks which can be viewed as generalizations of conventional neural network architectures. Finally, we will conclude by presenting applications based on the minimization of an asymmetric distance between the probability distribution of the $\phi^{4}$ machine learning algorithms and that of target probability distributions.<br>

# 第29回
日時: 7月1日10:30-11:30(JST)<br>
発表者: Lei Wang　氏 (Chinese Academy of Sciences)<br>
[講演スライド](./slides/Coulomb_gas-DLAP.pdf)<br>
発表題目:Fermi Flow: Ab-initio study of fermions at finite temperature <br>
概要：
Fermi Flow is a variational free energy approach to thermal properties of interacting fermions in the continuum. The approach builds on classic works such as Feynman's backflow transformation and DeWitt's quantized point transformation. Crucially, one can leverage modern computing techniques for these physical transformations by exploiting their connection to recent advances in deep learning, such as equivariant normalizing flows and neural ordinary equations. I will discuss promising results of Fermi Flow applied to the uniform electron gas, a fundamental problem in condensed matter and warm dense matter research. <br>

# 第28回
日時: 6月17日10:30-11:30(JST)<br>
発表者: 蘆田祐人　氏（東大）<br>
[講演スライド](./slides/DL_Physics_ashida.pdf)<br>
発表題目:差分進化を用いた最適なナノ熱機関の探索<br>
概要：最適な熱機関を探索する試みはカルノーの古典的な仕事以来、熱統計力学の中心的な課題の一つである。本講演では、進化的計算の一つである差分進化と呼ばれる手法を用いて、相互作用するナノ熱電系のうち熱力学的効率・パワーの意味で「最適」な熱機関を同定する試み[1]について紹介する。（時間が許せば）ベイズ推定の超解像推定への応用に関する研究についても簡単に紹介する。<br>
[1] YA and T. Sagawa, Commun. Phys. 4, 45 (2021).<br>

# 第27回
日時: 6月3日10:30-11:30(JST)<br>
発表者: 今泉允聡　氏（東京大学 先進科学研究機構）<br>
発表題目: 深層学習の汎化誤差解析：損失面由来の暗黙的正則化と深層モデルの二重降下<br>
概要：深層学習が高い汎化性能を達成するが、その原理の理論的解明は未だ発展途上の課題である。本講演では深層学習の性能を記述する、(i)損失面由来の暗黙的正則化、(ii)深層モデルのための二重降下、の2つの理論研究成果を紹介する。<br>
(i)暗黙的正則化は、学習アルゴリズムがニューラルネットワークモデルの自由度を暗黙的に制約することで、深層学習の過適合が防がれていることを主張する。ただし、深層ニューラルネットワークで実現する暗黙的正則化は明らかではなく、有力であるとされていた正則化の仮説（零点や学習初期値近傍）は近年の研究で強い批判を受けている。本研究では、深層ニューラルネットワークの損失面が多くの局所最小値を持ちかつ一定の仮定を満たすとき、この形状が学習アルゴリズム（確率的勾配降下法）の行動を制約し正則化を実現することを理論的に示す。またこのとき、深層ニューラルネットワークが正則化され、この汎化誤差がパラメータ数に依存しない上限を持つことを示す。<br>
(ii)二重降下をはじめとする漸近リスク解析は、モデルから定まる共分散構造のスペクトルを用いて、過剰なパラメータを持つモデルの汎化誤差を解析する理論的枠組みである。近年強い注目を集めて議論が進展しているが、この理論が適用できるのはランダム特徴量モデルやカーネル回帰などの特徴量に対する線形モデルに限られる。よって、層が多いニューラルネットワークなどの深層モデルへの適用可能性は未知数である。本研究は、線形性の制約を置かない一般的なモデル族について、最適化問題が尤度関数で定義されかつ一定の正則性を満たす時、この汎化誤差の上限が漸近リスクの理論に従うことを示す。さらにこの正則性条件を調べることで、並列化ニューラルネットなどの具体的な非線形・深層モデルが二重降下などの理論に従うことを示す。

# 第26回
日時: 5月20日10:30-11:30(JST)<br>
パネルディスカッション: テーマ「物理 x 深層学習 の未来」<br>
パネラー: 大槻東巳　氏（上智大理工）、樺島祥介(東大理／知の物理学研究センター)、田中章詞（理研iTHEMS/AIP 慶応数理）、富谷昭夫（理研BNL）、永井佑紀(原子力機構)<br>
情報提供: 野尻美保子(高エネルギー加速器研究機構)、福嶋健二 (東大理)<br>
概要: 2017年に開始された"Deep learning and physics"会合は、現在およそ1000名の登録者の方々が集うコミュニティに成長しました。そこで、これまでの「物理 x 機械学習」の研究の進展を振り返り、これからの研究の進展の可能性と方向を議論する機会を設けます。パネラーの方々そして情報提供の方々から今後の可能性についてプレゼンをいただき、それを元にパネラー間そして聴衆の方々と議論をすることで、これからの研究を加速する種とし、本コミュニティでの問題共有を行うとともに、チャンレンジする大きな課題を明確化します。

# 第25回
日時: 5月6日10:30-11:30(JST)<br>
発表者: 田中章詞　氏（理研iTHEMS/AIP 慶応数理）<br>
[講演スライド](./slides/20210506_atanaka.pdf)<br>
発表題目:識別器による最適輸送<br>
概要:深層学習を用いた潜在変数モデルの代表的な二つの例として、変分自己符号化器と敵対的生成ネットワークが知られています。これらは共に二つのネットワークを訓練するモデルです。変分自己符号化器は画像などのデータを潜在変数にエンコードする符号化器と、それをデコードして画像に戻す復号化器から構成されます。敵対的生成ネットワークは潜在変数から新たな画像を作り出す生成器と、それを本物と見分ける識別器から構成されます。変分自己符号化器ではそれぞれのネットワークが訓練後も明確な応用（符号化、復号化）を持ちますが、敵対的生成ネットワークの識別器は一見明確な応用先を持たないように思えます。本講演では最適輸送理論のアイデアを借用することで識別器を用いて生成器の画像生成の品質改善が可能[1]なことと、その他の識別器の応用について説明します。<br>
[1] Tanaka, A.. “Discriminator optimal transport.” NeurIPS (2019)<br>

# 第24回
日時: 4月22日10:30-11:30(JST)<br>
発表者: 堀江正信　氏（株式会社科学計算総合研究所、筑波大学システム情報工学研究群）<br>
[講演スライド](./slides/isogcn.pdf)<br>
発表題目:物理シミュレーションのための同変グラフニューラルネットワーク
<br> 
概要：グラフニューラルネットワーク (GNN) は、物理シミュレーションで広く用いられるメッシュデータに対して効率的に学習を行える機械学習モデルであり、これを用いることにより物理シミュレーションを高速化・高効率化することが期待されている。しかし、一般的な GNN は推論に時間がかかること、回転や平行移動といった座標変換に対する対称性 (同変性) を考慮していないなどの問題があった。そこで講演者らは、高速に推論できかつ座標変換に対する同変性を持つ GNN を提案した [1]。提案手法では、既存の同変 GNN では不可能であった、100 万頂点ほどの大規模グラフに対する高速な推論が可能であることが示されている。本講演では、提案手法およびその関連研究について述べる。なお、提案手法に関するソースコードは https://github.com/yellowshippo/isogcn-iclr2021 からダウンロード可能である。<br>
[1] M. Horie, N. Morita, T. Hishinuma, Y. Ihara, N. Mitsume. Isometric Transformation Invariant and Equivariant Graph Convolutional Networks, In International Conference on Learning Representations (ICLR), 2021 (arXiv: 2005.06316).<br>


# 第23回
日時: 4月8日10:30-11:30(JST)<br>
発表者: 富谷昭夫　氏（理研BNL）<br>
[講演スライド](./slides/cov-nn-dlap.pdf)<br>
発表題目:ゲージ共変なニューラルネットと4次元非可換ゲージ理論への応用（Gauge covariant neural network for 4 dimensional non-abelian gauge theory）
<br> 
概要：ニューラルネットの文脈でも物理においても対称性は本質的に重要である。本講演では、講演者らが開発したゲージ対称性を保つニューラルネットワークについて議論する。このニューラルネットワークは、リー群に値を取るベクトル場の間の写像を対称性を保ちながら実現する。従来のゲージ場のスメアリングやgradient flowは、固定パラメータを持つランク2テンソルのニューラルネットワークやneural ODEとみなすことができることを発見した。さらに活性化関数(スメアリングにおける規格化)の局所性を利用して、ゲージ共変ニューラルネットワークのバックプロパゲーションを導き出した。さらに学習則がうまくいくことを確認するために、動的フェルミオンを含む非可換ゲージ理論の系に対して、共変ニューラルネットワーク近似作用を用いた自己学習HMC（SLHMC）をもちいてシミュレーションを行った。結果としてHMCの結果をSLHMCが再現することを確認した。本講演は、[1]に基づく。<br>
[1] Akio Tomiya, Yuki Nagai, https://arxiv.org/abs/2103.11965<br>

# 第22回
日時: 3月11日10:30-11:30(JST)<br>
発表者: 松原祟　氏（大阪大学大学院基礎工学研究科）<br>
[講演スライドweb版](./slides/Matsubara_web.pdf)<br>
発表題目: エネルギー保存則など望ましい性質を持つ深層学習の設計について<br>
概要: "深い"ニューラルネットワークである深層学習は高い柔軟性を持ち，大規模なデータを学習することで，自動的に高度な意思決定システムを構築できるのだと説明されている．しかし，実際に深層学習が注目される契機となったのは畳み込みニューラルネットワークであり，平行移動不変性という特殊な性質を持っている．この性質によって，対象の位置のずれや微小な変形に対して堅牢な識別が可能になっている．類似したアイデアは，データの集合を入力として受け取るDeep Setsや，ノード間の順番を考慮しないグラフ畳み込みにも見られ，それぞれの分野で高い性能を発揮している．成功した深層学習は，ノーフリーランチ定理そのままに，何らかの性質を持つよう設計されている．<br>
このような考え方を物理学の世界に広げると，望ましい性質として物理の法則が挙げられる．近年ではハミルトニアンニューラルネットワークといい，ハミルトン系の基礎方程式を模倣することで，連続時間でエネルギー保存則が成り立つ物理シミュレーションを可能にするフレームワークが提案されている[1]．講演者らはさらに，ハミルトン系に限定されずエネルギーで記述された物理現象について，エネルギー保存則・散逸則を 離散時間において 厳密に保証するフレームワークを提案した[2]．本講演では，これらの研究に関する近年の動向を紹介するとともに，深層学習から見た物理学への期待についても述べる．<br>
[1] Sam Greydanus, Misko Dzamba, and Jason Yosinski, "Hamiltonian Neural Networks, " Advances in Neural Information Processing Systems (NeurIPS), 2019.<br>
[2] Takashi Matsubara, Ai Ishikawa, and Takaharu Yaguchi, "Deep Energy-Based Modeling of Discrete-Time Physics," Advances in Neural Information Processing Systems (NeurIPS), 2020.<br>

# 第21回
日時: 2月25日10:30-11:30(JST)<br>
発表者: 一木輝久　氏（名古屋大学未来社会創造機構）<br>
発表題目: ニューラルネットワークによる結び目の標準化<br>
概要: 典型的なニューラルネットワークはaffine変換と活性化関数を繰り返すことで実装されている．したがって活性化関数が狭義単調な連続関数の場合、ニューラルネットワークは入力データ空間の位相的性質を保存する変換を表現していることになる[1, 2]．そこで本講演ではニューラルネットワークを、トポロジーを不変に保つ変形を行う変換器として利用することを提唱する．具体的には結び目の上に配置した荷電粒子の反発エネルギーを最小化することによって、グチャグチャに折りたたまれた「汚い」結び目を、よりエネルギーの低い「標準的な」結び目へ変形するようニューラルネットワークの学習を行う．荷電粒子の物理モデルに勾配法などを適用すればニューラルネットワークは必要ないように思われるが、純粋な物理モデルで長さ一定の紐の上に束縛された粒子の運動を数値的に取り扱うのは容易ではない．このような利点を踏まえ、ニューラルネットワークは結び目を分類できるだろうか？という問いに対する取り組みを紹介する．<br>
[1] C. Olah, “Neural Networks, manifolds, and topology”, Blog post (2014).<br>
[2] M. Hajij and K. Istvan, “A topological framework for deep learning”, arXiv:2008.13697.<br>


# 第20回
日時: 2月18日10:30-11:30(JST)<br>
発表者: Hidenori Tanaka　氏 (Group Head & Senior Scientist at NTT Physics & Informatics Laboratories,Visiting Scholar at Stanford University)<br>
Daniel Kunin　氏 (Stanford University)<br>
[Slide](./slides/Neural_Mechanics_slides.pdf)<br>
発表題目: Neural Mechanics: Symmetry and Broken Conservation Laws in Deep Learning Dynamics<br>
（ご講演は英語）<br>
概要: Predicting the dynamics of neural network parameters during training is one of the key challenges in building a theoretical foundation for deep learning. A central obstacle is that the motion of a network in high-dimensional parameter space undergoes discrete finite steps along complex stochastic gradients derived from real-world datasets. We circumvent this obstacle through a unifying theoretical framework based on intrinsic symmetries embedded in a network's architecture that are present for any dataset. We show that any such symmetry imposes stringent geometric constraints on gradients and Hessians, leading to an associated conservation law in the continuous-time limit of stochastic gradient descent (SGD), akin to Noether's theorem in physics. We further show that finite learning rates used in practice can actually break these symmetry induced conservation laws. We apply tools from finite difference methods to derive modified gradient flow, a differential equation that better approximates the numerical trajectory taken by SGD at finite learning rates. We combine modified gradient flow with our framework of symmetries to derive exact integral expressions for the dynamics of certain parameter combinations. We empirically validate our analytic predictions for learning dynamics on VGG-16 trained on Tiny ImageNet. Overall, by exploiting symmetry, our work demonstrates that we can analytically describe the learning dynamics of various parameter combinations at finite learning rates and batch sizes for state of the art architectures trained on any dataset.<br>
Refs:<br>
[1] "Neural Mechanics: Symmetry and Broken Conservation Laws in Deep Learning Dynamics" (ICLR 2021)
Daniel Kunin*, Javier Sagastuy-Brena, Surya Ganguli, Daniel L.K. Yamins, Hidenori Tanaka*<br>
[2] "Pruning neural networks without any data by iteratively conserving synaptic flow" (NeurIPS 2020)
Hidenori Tanaka*, Daniel Kunin*, Daniel L. K. Yamins, Surya Ganguli


# 第19回
日時: 1月28日10:30-11:30(JST)<br>
発表者: James Halverson　氏 (Northeastern University, NSF AI Institute for Artificial Intelligence and Fundamental Interactions, co-organizes of Physics ∩ ML)<br>
[講演スライド](./slides/NN-QFT_DLAP.pdf)<br>
発表題目: Neural Networks and Quantum Field Theory<br>
（ご講演は英語）<br>
概要: We propose a theoretical understanding of neural networks in terms of Wilsonian effective field theory. The correspondence relies on the fact that many asymptotic neural networks are drawn from Gaussian processes, the analog of non-interacting field theories. Moving away from the asymptotic limit yields a non-Gaussian process and corresponds to turning on particle interactions, allowing for the computation of correlation functions of neural network outputs with Feynman diagrams. Minimal non-Gaussian process likelihoods are determined by the most relevant non-Gaussian terms, according to the flow in their coefficients induced by the Wilsonian renormalization group. This yields a direct connection between overparameterization and simplicity of neural network likelihoods. Whether the coefficients are constants or functions may be understood in terms of GP limit symmetries, as expected from 't Hooft's technical naturalness. General theoretical calculations are matched to neural network experiments in the simplest class of models allowing the correspondence. Our formalism is valid for any of the many architectures that becomes a GP in an asymptotic limit, a property preserved under certain types of training.<br>
[1] arXiv:2008.08601

# 第18回
日時: 1月14日10:30-11:30(JST)<br>
発表者: 鈴木大慈　氏(東京大学大学院 情報理工学系研究科数理情報学専攻)<br>
[講演スライド](./slides/Physics2021_public.pdf)<br>
発表題目: 無限次元勾配ランジュバン動力学による深層学習の最適化理論と汎化誤差解析<br>
概要: これまで統計的学習理論の枠組みにおいて深層学習の優位性が様々な
研究によって解明されてきたが，それらの多くはモデルの非凸性に起因
している．その意味で，深層学習の統計的な「良さ」を引き出すためには
，非凸最適化問題を避けることは難しいと考えられる．本講演では，
無限次元勾配ランジュバン動力学を用いて深層学習の非凸最適化問題を
解く手法を考察し，その汎化誤差を評価するための枠組みを提案する．
既存の平均場理論やニューラルタンジェントカーネル (NTK) といった
典型的な枠組みでは，大域的最適性を示すために横幅をサンプルサイズ
に合わせて無限大まで漸近させる必要があった．本講演では，より自然な
解析を実現するために深層学習の最適化を無限次元ランジュバン動力学
の観点から解析し，その大域的最適性および汎化性能の解析を行う．
本枠組みを用いることで，横幅が有限の場合も無限の場合も統一的に扱え，
さらに解がベイズ推定量に対応することから汎化誤差のバウンド及び
余剰誤差の速い収束レートが示せる．また，本手法によって得られた
推定量の予測誤差が任意の線形推定量を優越するような例が作れること
も示し，深層学習の有用性を最適化の保証付きで示す．



## 2020年
* [第17回：　本間希樹　氏「EHTによるブラックホールの撮像とスパースモデリング」](#第17回) 12/10
* [第16回：　入門講義「機械学習と物理」](#第16回) 11/26
* [第15回：　森貴司　氏 「深層学習の汎化の謎をめぐって」](#第15回) 11/12
* [第14回：　野尻美保子　氏 「ミンコフスキー汎関数を用いた機械学習の提案」](#第14回) 10/29
* [第13回：　Kazuhiro Terao　氏 「End-to-End, Machine Learning-based Data Reconstruction for Particle Imaging Neutrino Detectors」](#第13回) 10/15 (ご講演は英語）
* [第12回：　樺島祥介　氏 「スパース線形回帰に対する半解析的ブートストラップ法」](#第12回) 10/1
* [第11回：　藤井啓祐　氏 「NISQ (Noisy Intermediate-Scale Quantum technology) マシンを用いた量子機械学習」](#第11回) 9/17
* [第10回：　斎藤弘樹　氏 「強化学習を用いたボース・アインシュタイン凝縮体の制御」](#第10回) 9/3
* [第9回：　林祐輔　氏「表現学習の熱力学：深層生成モデルの物理法則を求めて」](#第9回) 8/20
* [第8回：　野村悠祐　氏「ボルツマンマシンを用いた量子多体波動関数表現：深層ボルツマンマシンによる厳密な表現と制限ボルツマンマシンによる数値的近似表現」 ](#第8回) 8/6
* [第7回：　本武陽一　氏「物理学者と学習機械の効果的な協業に向けて：学習済み深層ニューラルネットワークからの解釈可能な物理法則抽出」 ](#第7回) 7/30
* [第6回：　吉岡信行　氏「ニューラルネットワークで探る量子多体系の表現」 ](#第6回) 7/9
* [第5回：　福嶋健二　氏「物理学における観測と機械学習：中性子星の事例」 ](#第5回) 6/25
* [第4回：　唐木田亮　氏「深層学習の数理: 統計力学的アプローチ」 ](#第4回) 6/18
* [第3回：　ライトニングトーク](#第3回) 6/11
* [第2回：　橋本幸士　氏「深層学習と時空」](#第2回) 5/28
* [第1回：　永井佑紀　氏「精度保証された機械学習分子動力学法：自己学習ハイブリッドモンテカルロ法」](#第1回) 5/14


# 第17回
日時: 12月10日10:30-11:30(JST)<br>
発表者: 本間希樹　氏（国立天文台 水沢VLBI観測所）<br>
発表題目: EHTによるブラックホールの撮像とスパースモデリング<br>
概要：2019年4月、Event Horizon Telescope（EHT）プロジェクトによって、楕円銀河M87の中心にある巨大ブラックホールの影の写真が公表され、巨大ブラックホールの存在を示す視覚的な証拠として大きな話題となった。この写真は、世界中のミリ波電波望遠鏡を結ぶVLBI（Very Long Baseline Interferometry：超長基線電波干渉計）の観測手法を用いて撮影されたものである。電波干渉計の画像処理の基礎方程式は２次元フーリエ変換であるが、望遠鏡の台数が限られることから基礎方程式は劣決定となり、直接に逆フーリエ変換を実行することができない。このような問題を効率的に解くための手法として、我々はスパース性を制約として適切な解を得る「スパースモデリング」を用いて画像処理を行う解析手法を開発してきた。今回の講演では、電波干渉計によるブラックホール観測においてスパースモデリングや機械学習的なアプローチがどのように活用されているかについて紹介し、今後の展望についても合わせて述べたい。

# 第16回
日時: 11月26日10:30-12:00(JST)<br>
入門講義「機械学習と物理」<br>

第1部<br>
発表者: 田中章詞 氏(RIKEN iTHEMS/AIP)<br>
発表題目: 深層学習入門<br>
[講演スライド](./slides/DLAP2020intro_tanaka.pdf)<br>
概要:入門者向けにpythonの文法から深層学習フレームワークのミニマムな使い方の講義を行います。講義はgoogle colaboratoryを使って、実際にコードを触りながら行う予定です。<br>

第2部<br>
発表者: 富谷昭夫 氏(RIKEN BNL)<br>
発表題目: ニューラルネットを使った2次元イジング模型の相検出<br>
[手順書](./slides/Tomiya_howto_dlap2020.pdf)<br>
[Jupyter notebook(github)](./slides/DLAP2020_ising_detection.ipynb)<br>
[講演スライド](./slides/DLAP2020_lecture_tomiya_pub.pdf)<br>
概要: 本講義では、tensorflow/kerasを用いてNature Physics掲載の論文[1] の結果であるニューラルネットを使った2次元イジング模型の相転移の検出をおこないます。統計力学の初歩程度の知識を仮定します。<br>
[1] Juan Carrasquilla & Roger G. Melko, Nature Physics volume 13, pages431–434(2017)
<br>

# 第15回
日時: 11月12日10:30-11:30(JST)<br>
発表者: 森貴司　氏(RIKEN CEMS)<br>
[講演スライド](./slides/DL_Physics2020_mori.pdf)<br>
発表題目: 深層学習の汎化の謎をめぐって<br>
概要：現代的な深層学習の応用は，モデルに含まれるパラメータの数が訓練データのサンプル数よりも大きい，いわゆる過剰パラメータ領域 (overparameterized regime) でなされている．そのような領域で深刻な過剰適合 (overfitting) を示すことなく高い汎化性能が得られることは深層学習の大きな謎の一つである．この謎を理論的に解明しようとするときに重要だと思われる要素として，(i)モデルの特徴（ネットワークのタイプや深さ，広さなど），(ii)データの持つ構造（データの有効次元，局所性，対称性など），(iii)最適化アルゴリズムの特性（確率的勾配法などのダイナミクス）が挙げられる．<br>

(i)として最も単純な全結合ニューラルネットを考えると，モデルを特徴づけるのは隠れ層の数（深さ）および各隠れ層のニューロン数（広さ）である．深さと広さのどちらかを増やすことによって過剰パラメータ領域に到達できるが，これまでの研究では主に広さを増やしていったときの影響が調べられてきた．特に広さ無限大の極限でNeural Tangent Kernel (NTK)の理論が得られ，大きな注目の的になっている．一方で，ネットワークを深くしていったときに汎化性能がどのように変化するかについては理論的に不明な点が多い．<br>

私たちはネットワークの深さおよび広さが汎化にどのように影響するかを(ii)データの構造，特に分類ラベルの局所性の観点から調べた[1]．その結果，ネットワークの深さが汎化に良い影響をもたらすかどうかは分類ラベルの局所性に依存することがわかった．さらに，ネットワークの広さを増やしていっても必ずしもNTKの結果に収束しないことを示唆する結果が得られた．本講演では深層学習の汎化の謎とその理論的解明に向けた最近の研究についてレビューし，上記の私たちの結果について説明する．時間がゆるせば(iii)の話題として，汎化性能を向上させるための確率的勾配法の改良についての私たちの最近の研究[2]についても簡単に紹介したい．<br>

[1] Takashi Mori and Masahito Ueda, arXiv:2005.12488<br>
[2] Takashi Mori and Masahito Ueda, arXiv:2009.13094<br>

# 第14回
日時: 10月29日10:30-11:30(JST)<br>
発表者: 野尻　美保子　氏(高エネルギー加速器研究機構)<br>
[講演スライド](./slides/nojiri.pdf)<br>
発表題目: ミンコフスキー汎関数を用いた機械学習の提案<br>
概要：LHCなどで行われているコライダー実験では深層学習の利用がさかんです。この中で、強い相互作用（QCD) によって作られるジェット（ハドロン束）がどのようなプロセスから作られたかを深層学習で分類する問題は、新現象の探索に成果をあげています。深層学習を使ったジェット画像分類は、QCDとしてよい IRC(Infrared collinear) safe な指標だけを使ったジェット分類とくらべて、パフォーマンスが良いことがしられていました。<br>
今回のトークでは、ジェットの画像をミンコフスキー汎関数で一旦「測度空間」にマップした量(MS=Minkowski Sequence ) をIRC safe な量に加えた深層学習が、CNN による分類を超える結果をだすことを複数のベンチマークで示します。典型的なジェットの画像診断は、1000程度のinput を使いますが、新しい方法では、100 程度の情報しか使わないため、高速で安定した解析が可能です。MS は、CNN のフィルタリングアウトプットとして表現することができるため、CNNの画像診断には含まれていると考えるのが自然です。CNN のアウトプットにMS を追加することで、CNN がMS 以外の情報に集中させることが可能です。<br>
深層学習を利用すると物理解析のパフォーマンスが向上する場合には、通常の解析では取り入れられていない相関が含まれていると考えるべきでしょう。我々の研究の場合は、QCD の非摂動的な量をミンコフスキー汎関数を用いて少数の量で表すことで、摂動的な量と非摂動的な量との相関を安定的に利用できるようにしたと解釈することができます。この研究では深層学習のパフォーマンスに満足するのではなく、よりよい特徴空間を発見することが重要であるということをあらためて感じました。今後の イベント生成パッケージの向上、新物理の発見等への応用を検討していますが、宇宙などでの深層学習や、一般的な画像解析への応用についてもご意見をいただければと思っています。<br>
[1] M.Nojiri et al., to appear.<br>
[2] Neural Network-based Top Tagger with Two-Point Energy Correlations and Geometry of Soft Emissions. Amit Chakraborty, Sung Hak Lim, Mihoko M. Nojiri, Michihisa Takeuchi. JHEP 07 (2020) 111, JHEP 20 (2020) 111 (https://arxiv.org/abs/2003.11787)<br>
[3] 物理の人にはこれもよいと思います。K. R. Mecke, in Statistical Physics and Spatial Statistics, edited by K. R. Mecke and D. Stoyan (Springer Berlin Heidelberg, Berlin, Heidelberg, 2000) pp. 111–184.<br>

# 第13回
日時: 10月15日10:30-11:30(JST)<br>
発表者: Kazuhiro Terao 氏(SLAC スタンフォード国立加速器研究所)<br>
[講演スライド](./slides/2020-10-14-JapanSeminar.pdf)<br>
（ご講演は英語）
発表題目: End-to-End, Machine Learning-based Data Reconstruction for Particle Imaging Neutrino Detectors<br>
概要：With firm evidence of neutrino oscillation and measurements of mixing parameters, neutrino experiments are entering the high precision measurement era. The detector is becoming larger and denser to gain high statistics of measurements, and detector technologies evolve toward particle imaging, essentially a hi-resolution "camera", in order to capture every single detail of particles produced in a neutrino interaction. The forefront of such detector technologies is a Liquid Argon Time Projection Chamber (LArTPC), which is capable of recording images of charged particle tracks with breathtaking resolution. Such detailed information will allow LArTPCs to perform accurate particle identification and calorimetry, making it the detector of choice for many current and future neutrino experiments. However, analyzing hi-resolution imaging data can be challenging, requiring the development of many algorithms to identify and assemble features of the events in order to reconstruct neutrino interactions. In the recent years, we have been investigating a new approach using deep neural networks (DNNs), a modern solution to a pattern recognition for image-like data in the field of Computer Vision. A modern DNN can be applied for various types of problems such as data reconstruction tasks including interaction vertex identification, pixel clustering, particle type and flow reconstruction. In this talk I will discuss the challenges of data reconstruction for imaging detectors, recent work and future plans for developing a full LArTPC data reconstruction chain using DNNs.


# 第12回
日時: 10月1日10:30-11:30(JST)<br>
発表者: 樺島祥介　氏(東大理／知の物理学研究センター)<br>
[講演スライド](./slides/SemianalyticBS.pdf)<br>
発表題目:スパース線形回帰に対する半解析的ブートストラップ法<br>
概要：データからのパラメータ推定では必ず統計的なゆらぎが生じる．
古典的な推測統計学では，母集団分布と推定量の分布を「解析的に」関係づける
ことで，得られた推定量の確からしさを定量的に評価する．これにより，与えられた
信頼度の下での幅をもたせた推定（＝区間推定）や一定の有意水準の下での仮説の妥当性評価
（＝統計的検定）が可能になる．残念ながら，こうした解析的アプローチが可能なのは，
正規分布からサンプリングされたデータからの平均値の推定など，単純な
状況の場合に事実上限られる．母集団を表現する分布がわからない場合，あるいは，
わかっていても推定量が多次元の場合や導出に複雑な手続きを要する場合には
推定量がしたがう分布を解析的に導くことは難しい．
とはいえ，推定結果の不確実性を評価することはどのような場合であっても重要である．
ブートストラップ法はこうした困難に対する有力な対処法である．
この方法では，手元にあるデータが表す経験分布を母集団とみなす``plug-in principle''にしたがい，
経験分布からの復元抽出によって得られるデータに対する推定を何度も繰り返す
こと（＝リサンプリング）で推定量の分布を「数値的に」評価する．
ブートストラップ法はほぼすべての統計的推定／機械学習の方法に適用できる一方で，
リサンプリングに要する計算量がボトルネックになっている．
我々は，ランダム系の統計力学で発展した解析法であるレプリカ法と平均場近似を
組み合わせることで，スパース推定の代表的な方法であるleast absolute shrinkage and
selection operator (LASSO)に対し，リサンプリングを行うことなく，推定量の分布を
評価する近似法を開発した[1,2]．その内容について紹介する．<br>
[1] T. Obuchi and Y. Kabashima, Semi-Analytic Resampling in Lasso,
Journal of Machine Learning Research 20 (70), 1-33 (2019)<br>
[2] T. Takahashi and Y. Kabashima, Semi-analytic approximate stability selection
for correlated data in generalized linear models, arXiv:2003.08670;
to appear in Journal of Statistical Mechanics: Theory and Experiment<br>

# 第11回
日時: 9月17日10:30-11:30(JST)<br>
発表者: 藤井啓祐　氏(阪大基礎工)<br>
発表題目:NISQ (Noisy Intermediate-Scale Quantum technology) マシンを用いた量子機械学習<br>
[講演スライド](./slides/DeepLPhys_Fujii.pdf)<br>
講演概要: 
近年、GoogleやIBMなどの巨大IT企業が量子コンピュータの開発競争を繰り広げている。昨年Googleは、50量子ビットを超えるサイズの量子コンピュータを実現し、特定のタスクにおいてスーパーコンピュータよりも圧倒的に速く計算ができることを実証した。しかしながら、素因数分解など高速性が証明されている複雑な量子アルゴリズムの実行には、量子コンピュータの規模がまだ小さくノイズレベルも高い。このような、ノイズを含む小・中規模の量子コンピュータは、NISQ（Noisy Intermediate-Scale Quantum technology）と呼ばれている。このNISQマシンを、機械学習、量子化学計算、最適化などに応用するための研究が現在盛んに進められている。本セミナーでは、このような量子コンピュータを取り囲む現状を紹介し、NISQマシンを機械学習へと応用する、量子機械学習について紹介する。特に、量子ダイナミクスを用いて時系列データ処理を行う、量子レザバー計算[1]や、量子回路をモデルとして教師あり学習を行う量子回路学習[2]、そして、量子状態に特徴量を埋め込み量子コンピュータを用いてカーネルを推定する量子カーネル推定法[3]について、我々の研究も交えてご紹介する。<br>

[1] K. Fujii and K. Nakajima “Harnessing Disordered-Ensemble Quantum Dynamics for Machine Learning”, Phys. Rev. Applied 8, 24030 (2017).<br>
[2] K. Mitarai, M. Negoro, M. Kitagawa, and K. Fujii, “Quantum Circuit Learning”, Phys. Rev. A 98, 032309 (2018). <br>
[3] T. Kusumoto, K. Mitarai, K. Fujii, and M. Kitagawa, and M. Negoro, “Experimental quantum kernel machine learning with nuclear spins in a solid”, arXiv:1911.12021.<br>

# 第10回
日時: 9月3日10:30-11:30(JST)<br>
発表者: 斎藤弘樹　氏(電気通信大学基盤理工学専攻)<br>
発表題目:強化学習を用いたボース・アインシュタイン凝縮体の制御<br>
[講演スライド](./slides/DLAP2020Saito.pdf)<br>
講演概要: 
強化学習とは、「エージェント」がある「環境」の中で行動し「報酬」を受け取るという過程を経ながら、最適な行動を選択できるように学習するという、機械
学習の一手法である。最も有名な応用例は、囲碁で人間を打ち負かしたAlphaGoだろう。そこでは Deep-Q learning と呼ばれる、強化学習に深層ニューラルネットワークを組み入れた手法が使われている。最近、Deep-Q learning を物理の問題に応用するという研究も盛んに行われている。本講演では、超低温原子気体のボース・アインシュタイン凝縮体(BEC)のダイナミクスの制御に Deep-Q learning を応用した例を紹介する[1]。外部ポテンシャルによってBECをかき回すと、量子渦が生成されることが知られているが、Deep-Q learning によって外部ポテンシャルの動きを学習させ、望みの状態の量子渦が生成できることを示す。<br>
[1] H. Saito, J. Phys. Soc. Jpn. 89, 074006 (2020)<br>


# 第9回
日時: 8月20日10:30-11:30(JST)<br>
講演者: 林祐輔　氏（Japan Digital Design, Inc. ただし講演は個人としての活動）<br>
講演題目: 表現学習の熱力学：深層生成モデルの物理法則を求めて<br>
[講演スライド](./slides/DLAP2020slideyh.pdf)<br>
講演概要: 本講演では，深層生成モデルを熱力学と結びつけるいくつかの研究について紹介する．ベイズ統計と熱力学には形式的アナロジーが成り立つことが知られている[1]．その核にあるのは，ベイズ統計における損失関数が，熱力学における自由エネルギーと対応するというアイディアである．近年ではこのアナロジーを深層生成モデルにあてはめて，訓練が終了して平衡状態に落ち着いた深層生成モデルに対して熱力学第一法則や第二法則に相当するものが成り立つことを調べた研究がある[2]．ここでも損失関数として自由エネルギーが登場し，完全な熱力学関数のように振る舞う．しかし，このままでは損失関数と自由エネルギーの対応はアナロジーの域を出ず，統計的学習の背後にあるはずの学習プロセスを拘束する諸条件，“物理法則”に相当するものがみえてこないと講演者は感じている．深層生成モデルについて熱力学第一法則や第二法則以上の拘束条件は見出せないのだろうか？最近になって深層生成モデルを使った転移学習のプロセスに，準静的過程のアナロジーを持ち込んだ研究があらわれた[3]．深層生成モデルの損失関数は再構成誤差項や正則化項，分類誤差項などの要素からなるが，これらを温度にみたてて“等温準静的過程”を考えるのである．このような“熱力学的操作”を考えることで，損失関数の特定の要素の値を一定に保つ転移学習を行うことができる．この熱力学的操作を組み合わせればサイクルを考えることができ，その最大熱効率を与えるサイクルがカルノーサイクルであることを示すことができる．これは非平衡過程を含む転移学習プロセスの一つの拘束条件になっている．<br>
[1] Sumio Watanabe, Mathematical Theory of Bayesian Statistics, CRC Press (2018)<br>
[2] Alemi and Fischer, TherML: Thermodynamics of Machine Learning, arXiv:1807.04162 (2018)<br>
[3] Gao and Chaudhari, A Free-Energy Principle for Representation Learning, ICLR Workshop Integration of Deep Neural Models and Differential Equations (2020)<br>
[4] Hideaki Shimazaki, Neural Engine Hypothesis (Dynamic Neuroscience pp267-291), Springer (2017)<br>

# 第8回
日時:  8月6日10:30-11:30(JST)<br>
発表者: 野村悠祐　氏（理研CEMS）<br>
発表題目: ボルツマンマシンを用いた量子多体波動関数表現：深層ボルツマンマシンによる厳密な表現と制限ボルツマンマシンによる数値的近似表現<br>
[講演スライド](./slides/DLAP_2020_Nomura.pdf)<br>
概要： 指数関数的に大きな次元を持つ量子多体系の波動関数を有限個のパラメータで精度よく表すことは、物性物理のみならず素粒子、原子核、量子化学などに共通するグランドチャレンジである。本講演では機械学習で用いられるボルツマンマシンが量子多体波動関数表現に有用であることを紹介する。まず隠れ層が二層ある深層ボルツマンマシン(DBM)を用いて基底状態の波動関数を任意の精度で解析的に表現することが可能であることを示す[1]。これは経路積分を包含するより一般的な量子古典対応のフレームワークを提供するが、物理量計算に隠れ層自由度をモンテカルロサンプリングする必要性があるため負符号問題が生じる場合がある[1]。一方で、隠れ層が一層に制限された制限ボルツマンマシン(RBM)では、DBMのように解析的な表現はできないものの、数値的にパラメータを最適化することで、量子多体波動関数の表現が可能になる。RBMの良いところは解析的に隠れ層自由度をトレースアウトできるところであり、量子系の数値計算を行う上では負符号問題を回避できる点でDBMより利点がある場合がある。RBMを用いた手法は、フェルミオン系、フェルミオン-ボソン結合系、フラストレーションのあるスピン系な度への適用が進んでおり、それら一連の研究について紹介する[2-4]。<br>
[1] G. Carleo, Y. Nomura, and M. Imada, Nat. Commun. 9, 5322 (2018)<br>
[2] Y. Nomura, A. S. Darmawan, Y. Yamaji, and M. Imada, Phys. Rev. B 96, 205152 (2017)<br>
[3] Y. Nomura, J. Phys. Soc. Jpn. 89, 054706 (2020)<br>
[4] Y. Nomura and M. Imada, arXiv:2005.14142<br>

# 第7回
日時:  7月30日10:30-11:30(JST)<br>
発表者: 本武陽一 氏(統計数理研究所)<br>
[講演スライド](./slides/DLAP2020_7_mototake.pdf)<br>
発表題目: 物理学者と学習機械の効果的な協業に向けて：学習済み深層ニューラルネットワークからの解釈可能な物理法則抽出<br>
概要： 本講演では、力学系時系列データを学習した深層ニューラルネットワーク（DNN）から、解釈可能な物理則を抽出する手法を提案する[1]。
物理学は科学者の物理的洞察力によって大きく発展してきたが、アクティブマタや磁性体の磁区構造といった複雑な秩序構造を持つ系で洞察力を働かせることは時に困難である。これに対して、深層学習を始めとした複雑な高次元データをモデル化できる機械学習を用いた物理モデル構築手法の開発が近年活発に研究されている[1]。我々は、複雑なデータの内挿的モデル構築を得意とする機械学習と、物理的洞察によって大胆な理論の外挿を実現できる科学者の協業を実現することが重要と考え、これに繋がり得る手法を開発した。具体的には、物理データを学習したDNNから解釈可能な物理情報を抽出し科学者に提供することを目標として、有限自由度古典ハミルトン力学系とみなせる時系列データを学習したDNNから、系の隠れた保存則を推論する新しい手法を開発した。手法は、Noetherの定理と効果的なサンプリング法を元にDNNから力学系の対称性を抽出することで保存則を推論する。手法でDNNに課される前提は、学習に成功したDNNで広く成り立つと考えられている多様体仮説[3,4]のみであるため、手法は広範なDNNモデルに適用可能と考えられる。講演では、安定状態にある生物の集団運動を模擬した時系列データに提案手法を適用した事例等を紹介する。

[1] Interpretable Conservation Law Estimation by Deriving the Symmetries of Dynamics from Trained Deep Neural Networks, Y. Mototake, arXiv:2001.00111.<br>
[2] Hamiltonian neural networks, G. Samuel, M. Dzamba, and J. Yosinski, NeurIPS 2019 (arXiv:1906.01563).<br>
[3] Representation Learning: A Review and New Perspectives, Y. Bengio, C. Aaron, and V. Pascal, IEEE Trans. Pattern Anal. Mach. Intell., 35.8 (2013): 1798-1828.<br>
[4] Efficient representation of low-dimensional manifolds using deep networks, R. Basri and D.W., Jacobs, ICLR 2017 (arXiv:1602.04723).<br>


# 第6回
日時:  7月9日10:30-11:30(JST)<br>
発表者: 吉岡信行 氏(理研)<br>
発表題目: ニューラルネットワークで探る量子多体系の表現<br>
[講演スライド](./slides/202007_yoshioka_DLAP_seminar_send.pdf)<br>
従来より高い表現能力を持つことが知られていたニューラルネットワークは、近年の計算資源の向上・最適化手法の発達により、多くの機械学習タスクにおいて成功を収めている。
さらに、画像・音声などといった古典データに限らず、量子多体系の基底状態・励起状態などの表現に対しても有効であることが示された [1]。
次元性に依拠しない変分関数の構造は、量子多体系の大規模計算において用いられてきたテンソルネットワークと相補的に活用されることで、
多体現象の研究のフロンティアを押し拡げる役割を担うことが期待されている。
本講演では、ボルツマンマシンと呼ばれる種類のニューラルネットワークを導入し、その性質・応用について概観したのち、
講演者らによって見出された、開放量子多体系への適用可能性について議論する [2, 3]。

[1] G. Carleo and M. Troyer, Science 355, 602 (2017).<br>
[2] N. Yoshioka and R. Hamazaki, Phys. Rev. B 99, 214306 (2019).<br>
[3] N. Yoshioka et al., in preparation.<br>

# 第5回
日時: 6月25日10:30-11:30(JST)<br>
発表者: 福嶋健二 氏(東京大学)<br>
発表題目: 物理学における観測と機械学習：中性子星の事例<br>
[講演スライド](./slides/fukushima.pdf)<br>
概要: 学習、特に教師あり学習や強化学習とは、一言で表せば、最適化問題を解くということである。物理学は古来、最適化問題の効率向上に心血を注いできた学問であり、機械学習との親和性は高い。物理学における実験データの回帰分析に機械学習を応用するのは自然な発想だろう。例えば高エネルギー物理学ではジェットの識別に機械学習がその威力を発揮していることはよく知られている。しかし物理学の多くの回帰分析では、誤差のついたデータから誤差をつけたデータを引き出す必要があり、学習モデルはインプットが真値からずれている、ということも適切に学習せねばならない。本講演では中性子星の観測データから状態方程式を構築する問題を具体的な事例として採り上げ[1,2]、ひとつのアプローチ法を提案する。最後に、観測誤差を取り入れた学習が、ニューラルネットワークの重みの初期値依存性問題と密接に関係していることを議論する。<br>
[1] Y. Fujimoto, K. Fukushima, K. Murase, Phys.Rev.D 98 (2018) 2, 023019<br>
[2] Y. Fujimoto, K. Fukushima, K. Murase, Phys.Rev.D 101 (2020) 5, 054016<br>

# 第4回
日時: 2020年6月18日10:30-11:30(JST)<br>
発表者: 唐木田 亮 氏(産総研)<br>
発表題目: 深層学習の数理: 統計力学的アプローチ<br>

[登録フォーム](https://docs.google.com/forms/d/e/1FAIpQLSdJtfmkcJJ8gagNZ0_XJH7m5l1gPA4v0VsfxJUri5uxAOGSNA/viewform)

[講演スライド](./slides/DL_and_phys_2020_karakida_20200618.pdf)

概要: 本講演では, 深層学習の数理的な理解を目的とした近年の統計力学的解析を紹介する. 具体的には, 深層学習の平均場理論, ランダム行列理論, さらにNeural Tangent Kernel (NTK)理論をとおして学習ダイナミクスの理解へとつながる一連の流れを解説する. 
深層学習では, 性能の理論的な保証や, 最適なモデルや学習手法の設定に多くの課題があり, 数理的な研究が日進月歩で進んでいる. その中で統計力学的なアプローチは, 深層学習におけるパラメータ初期値がランダム行列であること, モデルの大自由度極限(ニューラルネットワーク各層の"幅"が十分に大きいこと)に着目した枠組みで, 様々なモデルアーキテクチャに普遍的に適応できる点に特徴がある. 平均場理論は, 勾配の大きさを巨視的変数として定式化することで, 訓練が進みやすいモデルとパラメータの設定を相転移によって定量的に説明する[1]. NTK理論は, 初期値まわりの摂動の範囲で学習が進む設定があることを発見し, 学習の大域収束と汎化性能に一定の理解を与える[2]. 
本講演ではこのような統計力学的アプローチを, 歴史的な背景も含めつつ簡単に概観したい. また, このアプローチを使うことで, 再急降下法のハイパーパラメータ(学習率)の設定指針[3]やBatch NormalizationとLayer Normalizationの効果の違い[4]のようなアルゴリズムの問題に対して, 定量的な説明を与えられることも紹介する.

[1] Deep information propagation. Samuel S Schoenholz, Justin Gilmer, Surya Ganguli and Jascha Sohl-Dickstein, ICLR 2017 (arXiv:1611.01232). <br>
[2] Neural tangent kernel: Convergence and generalization in neural networks. Arthur Jacot, Franck Gabriel and Clément Hongler, NeurIPS 2018 (arXiv:1806.07572). <br>
[3] Universal Statistics of Fisher Information in Deep Neural Networks: Mean Field Approach. RK, Shotaro Akaho and Shun-ichi Amari, AISTATS 2019 (arXiv:1806.01316).<br>
[4] The Normalization Method for Alleviating Pathological Sharpness in Wide Neural Networks. RK, Shotaro Akaho and Shun-ichi Amari, NeurIPS 2019 (arXiv:1906.02926).<br>


# 第3回　

第三回(6/11)は、ライトニングトークで構成されます。<br>
日時: 2020年6月11日10:30-11:30(JST)<br>
発表者：希望者<br>

講演者: 野村悠祐 氏(理研CEMS)<br>
講演題目: 深層ボルツマンマシンを用いた量子多体波動関数の厳密な構築<br>
講演概要: 量子多体系の波動関数を深層ボルツマンマシンを用いて厳密に表現する方法を紹介する(Carleo, Nomura, Imada, Nature Communications 2018)。<br>

[講演スライド](./slides/Nomura_presentation_2020_06_11.pdf)

講演者: 林祐輔 氏(Japan Digital Design, Inc. ただし講演は個人としての活動)<br>
講演題目: 表現学習の確率熱力学的解釈<br>
講演概要: 表現学習とは，画像，音声，自然言語，時系列データといった多様な生データから，目的のタスクを解くために意味のある特徴量を生成する方法を，統計モデル自身に考えさせるアプローチのことを指す．この発表では，表現学習と確率熱力学の間にアナロジーが成り立つことを紹介し，準静的過程に対応する熱力学的操作が転移学習のようなデータのドメインを跨ぐ学習において有用であることを説明する．<br>

[講演スライド](./slides/Hayashi_DLAP2020.pdf)

講演者: 北沢正清 氏(大阪大学)<br>
講演題目: SU(3)非可換ゲージ理論のトポロジー分類への機械学習の適用<br>
講演概要: 4次元畳み込みニューラルネットワークを用いて、SU(3)非可換ゲージ理論の多次元データを学習し、トポロジカル電荷を推定した。99%という高い正答率を得た成果などを報告する。<br>

[講演スライド](./slides/Kitazawa_200611DLAP_NNQ.pdf)


講演者: 大塚啓　氏(KEK)<br>
講演題目: 深層学習を用いた弦理論のランドスケープ<br>
講演概要: 本講演では、背景磁場のあるCalabi-Yau 多様体上にコンパクト化されたヘテロ型弦理論に対して、深層学習の一種であるオートエンコーダーによる次元削減とクラスタリングを適用する。 特に、フェルミオンの世代数と余剰次元空間の曲率に強い相関があることを紹介する[1]。[1] H. Otsuka and K. Takemoto, JHEP 05 (2020), 047.<br>

[講演スライド](./slides/Otsuka_20200611.pdf)

講演後には、参加者に「さらに詳しく聞きたい講演」についてのアンケートを実施し、そのアンケート結果をもとに、今後のオンラインセミナーの講演を決めていこうと考えています。<br>

[発表希望者用フォーム](https://docs.google.com/forms/d/e/1FAIpQLSfFsyop94o5mV_2ab6qB_PjpWGUN_77C_dZ44hjmXGC_MHEKg/viewform)

[参加希望者（発表なし）用フォーム](https://docs.google.com/forms/d/e/1FAIpQLSfXiD5kB106iFpglgvTa_TjvoDH03EPFRB1hkSS8N0GZNyrjQ/viewform)


ライトニングトークの構成は以下の通りです：<br>
　１）ご講演は３-10分間、その後の質疑応答は２分間、合計で５-15分間となります。<br>
　　（講演時間が終了すると座長から終了のお知らせがありますのでご協力お願いします）<br>
　２）スライドはpdf (pptもしくはkeynote)数枚です。<br>
　　　講演タイトルと所属、お名前、メールなどの連絡先を記載ください。<br>
　　　見本として[次のもの](./slidesample.pdf)をご参考に。<br>
　３）講演＋質疑時間の５分間が終了した後は、チャット機能で、参加者からの質問にお答えください。<br>
　４）ご講演タイトル（仮）を、上記登録フォームで記入ください。<br>
発表者希望者の締切は6/9の夜11時とします。<br>
発表内容は、ご自身あるいは共同研究者のオリジナルな研究に限ります。<br>

# 第2回
日時: 2020年5月28日10:30-11:30(JST)<br>
発表者: 橋本幸士　氏(大阪大学)<br>
発表題目: 深層学習と時空

[登録フォーム](https://docs.google.com/forms/d/e/1FAIpQLSeWYyvnJC-sHLrit6d-RebOaaDeBFEFc3wsMtlASIJRniLGEg/viewform)

[講演スライド](./slides/Hashimoto20200528.pdf)

概要：
本講演では、深層ニューラルネットワークを時空とみなせるかどうかについて、議論する。特に、量子重力理論として研究が進むホログラフィー原理そのものを深層学習とみなす手法について紹介する。
学習されたニューラルネットワークの解釈可能性は、機械学習を物理学に応用する際に最も重要な観点の一つである。ニューラルネットワークの構造を対称性などにより規定することで制約を加え解釈可能にすることは学習を効率的にすることにつながっている。一方で、深層ボルツマンマシンはそもそもスピン系が原子配列しているものの一般化と考えられることから、ニューラルネットワークそのものが時空として機能している例が存在している。このような中で、量子重力理論と機械学習の融合を目指す研究が生まれた。この20年間の量子重力理論の研究において、最も重要な位置を占めているのはホログラフィー原理[1]であり、そこでは、量子重力理論と等価な、重力を含まない（時空次元の低い）量子系が存在し、重力の時空はそこから創発する。このホログラフィー原理で創発する時空を、教師つき学習の深層ニューラルネットワークと同一視し、時空のメトリックを重みと考えることで、創発時空を量子系のデータから決定する手法[2][3][4]を本講演では紹介する。

[1] The Large N limit of superconformal field theories and supergravity Juan Martin Maldacena Published in: Int.J.Theor.Phys. 38 (1999) 1113-1133, Adv.Theor.Math.Phys. 2 (1998) 231-252 • e-Print: hep-th/9711200 [hep-th]<br>
[2]Deep learning and the AdS/CFT correspondence Koji Hashimoto, Sotaro Sugishita, Akinori Tanaka, Akio Tomiya Published in: Phys.Rev.D 98 (2018) 4, 046019 • e-Print: 1802.08313 [hep-th]<br>
[3] Deep Learning and Holographic QCD Koji Hashimoto, Sotaro Sugishita, Akinori Tanaka, Akio Tomiya
Published in: Phys.Rev.D 98 (2018) 10, 106014 • e-Print: 1809.10536 [hep-th]<br>
[4] Deep Learning and AdS/QCD Tetsuya Akutagawa, Koji Hashimoto, Takayuki Sumimoto e-Print: 2005.02636 [hep-th]<br>


# 第1回
日時: 2020年5月14日10:30-11:30(JST)<br>
発表者: 永井佑紀　氏(原子力機構)<br>
発表題目: 精度保証された機械学習分子動力学法：自己学習ハイブリッドモンテカルロ法 

[登録フォーム](https://docs.google.com/forms/d/e/1FAIpQLSedDoIH3RW6skBAzu84BkZ8yJTapYxC237BztfnPGhVdGgLLg/viewform)

[講演スライド](./slides/Nagai_SLHMC20200514.pdf)

概要：
本講演では、2008年に開発された機械学習分子動力学法について解説するとともに、学習精度に計算精度が依存しない機械学習シミュレーションである自己学習ハイブリッドモンテカルロ法について紹介する。<br>
第一原理計算で得られたポテンシャルを再現するようなニューラルネットワーク(ANN)を構築して分子動力学を実行するのが機械学習分子動力学法である。ANNを構築する際の最適なトレーニングデータは、元々の第一原理分子動力学法で生成される原子配置とそのポテンシャルである。しかしながら、第一原理分子動力学法の計算負荷が高いために機械学習分子動力学法を用いるのであるから、元々の第一原理分子動力学法でデータを集めるのは本末転倒である。そのため、通常は、様々な原子配置とそのポテンシャルデータを大量に作成することで、目的の機械学習分子動力学法と同じようなポテンシャルを生成するANNを構築している。しかしながら、構築されたANNが元々の第一原理計算のポテンシャルを再現するという保証はない。さらに、4元素以上で構成されるような系の場合には、長時間の機械学習分子動力学法では計算が不安定になることがあり、機械学習分子動力学法の計算の精度や妥当性については常に慎重な議論が必要であった。<br>
本講演では、自己学習モンテカルロ法のアイディア[1]を用いることで、得られた結果が統計的に厳密にオリジナルの第一原理計算分子動力学法の計算結果と等しい手法を開発したことを報告する[2]。
そして、その手法を用いて、4元素系でも精度よく計算ができることを示すため、フォノン誘起超伝導体YNi2B2Cのフォノン計算の結果を報告する。<br>

[1] J. Liu, Y. Qi, Z. Y. Meng, and L. Fu, Phys. Rev. B 95, 041101(R) (2017).; J. Liu, H. Shen, Y. Qi, Z. Y. Meng, and L. Fu, Phys. Rev. B 95, 241104(R) (2017).; YN, H, Shen, Y. Qi, J. Liu, and L. Fu, Phys. Rev. B 96, 161102(R) (2017)<br>
[2] YN, M. Okumura, K. Kobayashi and M. Shiga, arXiv:1909.02255<br>













